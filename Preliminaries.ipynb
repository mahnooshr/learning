{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcoDdZ12QETFwIz6U1aYGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahnooshr/learning/blob/main/Preliminaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preliminaries\n",
        "##Data Manipulation\n",
        "\n",
        "<details>\n",
        "  <summary>Getting Started</summary>\n",
        "  <p>This is an initial version of our journey in deep learning code</p>\n",
        "</details>"
      ],
      "metadata": {
        "id": "zgbc4PyOK2nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1YhB-N_uq2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Et2CIGTNLW-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(10, dtype=torch.float64)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3d0Tp3_QFr3",
        "outputId": "e7146212-a148-41db-db5c-7e51d1a539e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVTyuhfZRlW0",
        "outputId": "ff7228b9-7895-4f65-938c-d7ae6ec05b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.reshape(5,2)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toK7MjaGR0_Z",
        "outputId": "f10e3400-8e31-484e-b4f7-44f0a2210d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.],\n",
              "        [6., 7.],\n",
              "        [8., 9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2,3,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvL9oVMwSqcW",
        "outputId": "84258339-7621-490f-864d-900f9739061d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(1,2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVx6ToOpTTPQ",
        "outputId": "efcee45c-cf87-415d-8478-4c2aba444bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.],\n",
              "         [1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aixJA9IDTY4k",
        "outputId": "8f9ee216-32e3-4f7a-91d6-fb12882d81e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8113, 0.9495, 0.4007, 0.5443, 0.7093],\n",
              "        [0.1547, 0.5261, 0.5460, 0.6203, 0.1085],\n",
              "        [0.8506, 0.2126, 0.9356, 0.5652, 0.5360]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1,2],[3,4],[5,6]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJsW6ppMTvJH",
        "outputId": "164172dd-bff2-42b1-e8f2-51c476bbbcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Indexing and Slicing"
      ],
      "metadata": {
        "id": "dOPn-wkXVF4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhWjvmY5VRuL",
        "outputId": "dd3906a4-0e75-4426-9665-f867c177635e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [2., 3.],\n",
              "        [4., 5.],\n",
              "        [6., 7.],\n",
              "        [8., 9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QdP1KNeVVSo",
        "outputId": "cbf9f648-ead3-47c3-94ba-0dfc9f0a9d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8., 9.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[2:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JINjdsKQV6AQ",
        "outputId": "59b93b49-fa0e-4d73-85cd-a3c8b0cfbfef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4., 5.],\n",
              "        [6., 7.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[3,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPQQFn22V-Gp",
        "outputId": "6993bc89-a897-416c-f379-b0818b2daca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7., dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[3,1]=10\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unCeLCYWWOhp",
        "outputId": "34247187-231a-4b14-a4e8-615ff3c3ba4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.],\n",
              "        [ 2.,  3.],\n",
              "        [ 4.,  5.],\n",
              "        [ 6., 10.],\n",
              "        [ 8.,  9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:3,:]=7\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KODlWUMSWSVj",
        "outputId": "1a0c1f21-3fd3-4477-cb03-c0564495d802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.,  7.],\n",
              "        [ 7.,  7.],\n",
              "        [ 7.,  7.],\n",
              "        [ 6., 10.],\n",
              "        [ 8.,  9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:3,:2]=5\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOhpEVcpYchv",
        "outputId": "f0cdb04c-b206-4c19-b8bd-9f4b3662e0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 6., 10.],\n",
              "        [ 8.,  9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Operations"
      ],
      "metadata": {
        "id": "Qegtl8R3YvLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1, 2, 3, 4])\n",
        "b = torch.tensor([5, 6, 7, 8])\n",
        "a + b, a - b, a * b, a / b, a ** b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIj_VVg-Y3lg",
        "outputId": "54ffbbc9-7974-466f-bab4-0f4c7e6d356a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 6,  8, 10, 12]),\n",
              " tensor([-4, -4, -4, -4]),\n",
              " tensor([ 5, 12, 21, 32]),\n",
              " tensor([0.2000, 0.3333, 0.4286, 0.5000]),\n",
              " tensor([    1,    64,  2187, 65536]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwDm4w3ubLKC",
        "outputId": "aa67b9d3-2110-47e0-f659-7bd939f6c743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 6., 10.],\n",
              "        [ 8.,  9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETXknSyVa52I",
        "outputId": "020e203a-3860-450a-9f88-7ba5c9e3021c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  148.4132,   148.4132],\n",
              "        [  148.4132,   148.4132],\n",
              "        [  148.4132,   148.4132],\n",
              "        [  403.4288, 22026.4658],\n",
              "        [ 2980.9580,  8103.0839]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.arange(12).reshape(3,4)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Vzmmmjb82D",
        "outputId": "85cbdbde-0c79-40e4-a4f8-9a47255ca4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ewxw3zldu1X",
        "outputId": "82fad788-71c5-452c-dff6-1b94714759bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 1., 4., 3.],\n",
              "        [1., 2., 3., 4.],\n",
              "        [4., 3., 2., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a == k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dctjqLy2egJ0",
        "outputId": "9ba1fb31-d415-4f4d-f6a6-19c5adb380f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat((a, k), dim=0), torch.cat((k, a), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFk6rm3c7yY",
        "outputId": "aa051a43-04ec-4873-aaa6-a224120741a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [ 2.,  1.,  4.,  3.],\n",
              "         [ 1.,  2.,  3.,  4.],\n",
              "         [ 4.,  3.,  2.,  1.]]),\n",
              " tensor([[ 2.,  1.,  4.,  3.,  0.,  1.,  2.,  3.],\n",
              "         [ 1.,  2.,  3.,  4.,  4.,  5.,  6.,  7.],\n",
              "         [ 4.,  3.,  2.,  1.,  8.,  9., 10., 11.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVoDSSDcele9",
        "outputId": "b97dfa60-1fca-4d0a-933c-b7ea1e69f1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Broadcasting"
      ],
      "metadata": {
        "id": "kc98JyjqgPIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m=torch.arange(3).reshape(1,3)\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpY7Y_lLewtB",
        "outputId": "a0518930-385f-436d-aff5-8e1f92ad2e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=torch.arange(5).reshape(5,1)\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmgVcYQUf5Vr",
        "outputId": "5275d3f9-85ae-4f81-dda4-d0c9041bf6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [1],\n",
              "        [2],\n",
              "        [3],\n",
              "        [4]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m+n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f32AvL5PgCM5",
        "outputId": "6c6344a4-9112-4bdd-c7fc-c93851465b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [1, 2, 3],\n",
              "        [2, 3, 4],\n",
              "        [3, 4, 5],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving Memory"
      ],
      "metadata": {
        "id": "_esyMlCYgv3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before = id(m)\n",
        "m = m + n\n",
        "id(m) == before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOqaiOrlgIQF",
        "outputId": "d6cfd83f-d946-4922-8170-47cc3319cc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = id(m)\n",
        "m += n\n",
        "id(m) == before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_6PnJ4aol1k",
        "outputId": "11ddf45a-4446-47b3-e3f4-d2b27ba59989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzCPHHtmn-q0",
        "outputId": "9edb4cd5-c55c-48a2-94e3-d7eddc352281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 6., 10.],\n",
              "        [ 8.,  9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=torch.ones_like(x)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTb06jwDhQke",
        "outputId": "6a34103c-2bd6-4f49-814b-ed2922ad09b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.],\n",
              "        [1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(id(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwya4oCcndIw",
        "outputId": "f6cddf3f-0381-4367-a665-abc98cad35a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136976083066832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t[:]=t+x\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgc5DLPinjPe",
        "outputId": "e685f180-24c2-4358-d4f3-c63dc49d14d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  6.],\n",
              "        [ 6.,  6.],\n",
              "        [ 6.,  6.],\n",
              "        [ 7., 11.],\n",
              "        [ 9., 10.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(id(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtAn9ikWoC_K",
        "outputId": "d1dcbcc5-d0d3-4407-d9f0-b2158ea68e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136979203216528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert to torch Objects"
      ],
      "metadata": {
        "id": "QoLubqfrovLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = x.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKcBi1xTowkP",
        "outputId": "f4956957-2069-4c06-e85c-558d29aebab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([3.5])\n",
        "a, a.item(), float(a), int(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31oJpndqpdbi",
        "outputId": "f637345f-4a70-4fd1-c24f-0be7560e0e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercises"
      ],
      "metadata": {
        "id": "-Mk8naMnqUCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1"
      ],
      "metadata": {
        "id": "NWCrqVooqZIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=torch.arange(20).reshape(4,5)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_RVoKbiqctv",
        "outputId": "442a3efc-5a62-4fc8-e242-9454e9e01b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 5.,  5.],\n",
              "        [ 6., 10.],\n",
              "        [ 8.,  9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C =torch.ones_like(X)\n",
        "C"
      ],
      "metadata": {
        "id": "tIFJEf4yr7ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C==X,Y>C,Y<C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TanhKj5Xrrl9",
        "outputId": "e07b28a2-9eb2-4050-84a7-8ad4e4cfef4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[False,  True, False, False, False],\n",
              "         [False, False, False, False, False],\n",
              "         [False, False, False, False, False],\n",
              "         [False, False, False, False, False]]),\n",
              " tensor([[False, False,  True,  True,  True],\n",
              "         [ True,  True,  True,  True,  True],\n",
              "         [ True,  True,  True,  True,  True],\n",
              "         [ True,  True,  True,  True,  True]]),\n",
              " tensor([[ True, False, False, False, False],\n",
              "         [False, False, False, False, False],\n",
              "         [False, False, False, False, False],\n",
              "         [False, False, False, False, False]]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2"
      ],
      "metadata": {
        "id": "W4IWXSAOsaoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r=torch.arange(4).reshape(4,1)\n",
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqW-TB6Hsb7p",
        "outputId": "b5763c2b-08cb-4f1d-dd2f-9162ffc2a044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [1],\n",
              "        [2],\n",
              "        [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e=torch.arange(3).reshape(1,3)\n",
        "e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCx3x2aLsoly",
        "outputId": "5f2c4d05-b4b4-4004-e190-aa0442d79b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r+e"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YySVti-Wsvki",
        "outputId": "13023403-9a2a-47de-b718-94706425d6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [1, 2, 3],\n",
              "        [2, 3, 4],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8dgSS6nStD8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'school.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('''NUMSTUDENT,classType,grade\n",
        "20,a,3\n",
        "NA,a,5\n",
        "40,NA,1\n",
        "10,a,7''')"
      ],
      "metadata": {
        "id": "CilaC2e2IKyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "GWqLzO_eut6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "q6rsn4siuy9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsCpsgiHk4U",
        "outputId": "55d20fd7-cb45-41bb-ff60-7c9fa2dd44fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NUMSTUDENT classType  grade\n",
            "0        20.0         a      3\n",
            "1         NaN         a      5\n",
            "2        40.0       NaN      1\n",
            "3        10.0         a      7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NaN is a missing value\n",
        "\n",
        " imputation:replaces missing values with estimates of their values\n",
        "\n",
        " deletion:discards either those rows or those columns that contain missing values\n"
      ],
      "metadata": {
        "id": "woaHrspwJ1Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRrxdgeUJJ1n",
        "outputId": "c8916926-9a7f-408b-b5ad-bf44b40e9f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NUMSTUDENT  classType_a  classType_nan\n",
            "0        20.0            1              0\n",
            "1         NaN            1              0\n",
            "2        40.0            0              1\n",
            "3        10.0            1              0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mean value"
      ],
      "metadata": {
        "id": "sguQopvJ9Nyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A3_opXmMUPw",
        "outputId": "fae8a2e1-4069-4442-f1fe-46201511bd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NUMSTUDENT  classType_a  classType_nan\n",
            "0   20.000000            1              0\n",
            "1   23.333333            1              0\n",
            "2   40.000000            0              1\n",
            "3   10.000000            1              0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to tensor"
      ],
      "metadata": {
        "id": "UCxyosSngAAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "\n",
        "r = torch.tensor(inputs.to_numpy(dtype=float))\n",
        "e = torch.tensor(targets.to_numpy(dtype=float))\n",
        "r, e"
      ],
      "metadata": {
        "id": "1mkmKCqmgjDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercises"
      ],
      "metadata": {
        "id": "mmbptXfXg8Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "_c2siG13g-U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data=pd.read_csv('/content/iris.data', names=[\"a\",\"b\",\"c\",\"d\",\"e\"])\n",
        "data.describe(include=\"all\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "HD00nNjSkn5E",
        "outputId": "05f9f053-5db6-456d-b1a9-84ded4396997"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 a           b           c           d            e\n",
              "count   150.000000  150.000000  150.000000  150.000000          150\n",
              "unique         NaN         NaN         NaN         NaN            3\n",
              "top            NaN         NaN         NaN         NaN  Iris-setosa\n",
              "freq           NaN         NaN         NaN         NaN           50\n",
              "mean      5.843333    3.054000    3.758667    1.198667          NaN\n",
              "std       0.828066    0.433594    1.764420    0.763161          NaN\n",
              "min       4.300000    2.000000    1.000000    0.100000          NaN\n",
              "25%       5.100000    2.800000    1.600000    0.300000          NaN\n",
              "50%       5.800000    3.000000    4.350000    1.300000          NaN\n",
              "75%       6.400000    3.300000    5.100000    1.800000          NaN\n",
              "max       7.900000    4.400000    6.900000    2.500000          NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07b92b9c-5366-44f2-8ebb-3d121c415430\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.054000</td>\n",
              "      <td>3.758667</td>\n",
              "      <td>1.198667</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>1.764420</td>\n",
              "      <td>0.763161</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07b92b9c-5366-44f2-8ebb-3d121c415430')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07b92b9c-5366-44f2-8ebb-3d121c415430 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07b92b9c-5366-44f2-8ebb-3d121c415430');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-27b8c048-87b6-4b95-b94d-a0d508458bbf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27b8c048-87b6-4b95-b94d-a0d508458bbf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-27b8c048-87b6-4b95-b94d-a0d508458bbf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.24711349471842,\n        \"min\": 0.828066127977863,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.843333333333334,\n          5.8,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.08647211421483,\n        \"min\": 0.4335943113621737,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.0540000000000003,\n          3.0,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.835227940958106,\n        \"min\": 1.0,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.758666666666666,\n          4.35,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52.636634243409915,\n        \"min\": 0.1,\n        \"max\": 150.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.1986666666666668,\n          1.3,\n          150.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"50\",\n          \"150\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Algebra"
      ],
      "metadata": {
        "id": "QLDp2b4ykROe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vectors"
      ],
      "metadata": {
        "id": "OYxl0wE7wSps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x=torch.arange(5)\n",
        "x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Px0tgCzuJh2",
        "outputId": "32219d3f-f557-4f27-8597-4a4bd6fd3fef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRBTFP9nwuyn",
        "outputId": "6104671c-ce35-4d46-cbc8-72d6f7d6593b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ITxRsjUww3b",
        "outputId": "f9e6f482-d190-4f72-aa30-1e5117d506c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrices"
      ],
      "metadata": {
        "id": "cwQoCbO_w28M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A=torch.arange(12).reshape(3,4)\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkvItSQ6w0DG",
        "outputId": "afb6fb51-772b-4762-fab4-b988a088c943"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_OeqZ7xVYu",
        "outputId": "c835dbe9-2f27-4a50-bf97-4f799645fffc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  4,  8],\n",
              "        [ 1,  5,  9],\n",
              "        [ 2,  6, 10],\n",
              "        [ 3,  7, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "symmetric"
      ],
      "metadata": {
        "id": "oFFXn1-Qx8_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
        "A == A.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LgS-oAGx28y",
        "outputId": "4ef7ffbb-339e-4dfb-cdd9-b1c0fdde5ad4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
        "B = A.clone()\n",
        "A,B,id(A)==id(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9FzAZfkyEKR",
        "outputId": "febd0049-75cd-46cd-a472-247012d9fd0c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 1., 2.],\n",
              "         [3., 4., 5.]]),\n",
              " tensor([[0., 1., 2.],\n",
              "         [3., 4., 5.]]),\n",
              " False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A * B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoWv8tuWyglI",
        "outputId": "9002c1bb-24c7-494e-ae2a-e23291d9bb87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  4.],\n",
              "        [ 9., 16., 25.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2\n",
        "X = torch.arange(24, dtype=torch.float64).reshape(2, 3, 4)\n",
        "a,X,a+X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNh4YKh5yur_",
        "outputId": "1e85a9da-6caa-4c5b-ee1d-2086f79d89ca"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " tensor([[[ 0.,  1.,  2.,  3.],\n",
              "          [ 4.,  5.,  6.,  7.],\n",
              "          [ 8.,  9., 10., 11.]],\n",
              " \n",
              "         [[12., 13., 14., 15.],\n",
              "          [16., 17., 18., 19.],\n",
              "          [20., 21., 22., 23.]]], dtype=torch.float64),\n",
              " tensor([[[ 2.,  3.,  4.,  5.],\n",
              "          [ 6.,  7.,  8.,  9.],\n",
              "          [10., 11., 12., 13.]],\n",
              " \n",
              "         [[14., 15., 16., 17.],\n",
              "          [18., 19., 20., 21.],\n",
              "          [22., 23., 24., 25.]]], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6ZcGqCUzHTP",
        "outputId": "2ffb7de2-2b6f-44e0-9bc5-1f32f20b885f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(276)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBgWNGXpzRDO",
        "outputId": "a017f0a2-f746-40c4-c59a-eee8d07da0ad"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12, 14, 16, 18],\n",
              "        [20, 22, 24, 26],\n",
              "        [28, 30, 32, 34]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUWWNkULzppc",
        "outputId": "850879dd-7ba0-410f-e2c1-4eeaee904a89"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12, 15, 18, 21],\n",
              "        [48, 51, 54, 57]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum(axis=[0, 1]).sum()==X.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm78GcZGz4MT",
        "outputId": "a2a6ff32-0e81-41df-afe0-84d6aed7994d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.mean()== X.sum()/X.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTzHC4Kh0Ccc",
        "outputId": "81306544-6e85-4257-bd53-65ab09db420b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "Y=torch.arange(8).reshape(4,2)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hZsSuNvR9Li",
        "outputId": "0e2fc7ef-d4ac-41b9-82c9-96b07825abea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5],\n",
              "        [6, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cumulative Sum"
      ],
      "metadata": {
        "id": "i6RAHnwOVN9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y.cumsum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmHbtvIFCrTq",
        "outputId": "7d7fa33c-3738-4bbc-91a5-acc1911225fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 2,  4],\n",
              "        [ 6,  9],\n",
              "        [12, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(3)\n",
        "y=torch.arange(3)\n",
        "x,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdjICxkLjfeZ",
        "outputId": "3891852b-4708-4cf6-833b-baa2beaf8a00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2]), tensor([0, 1, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inner product"
      ],
      "metadata": {
        "id": "kK40nH0TjVGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.dot(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnoYj6IoVPhF",
        "outputId": "180fbd45-2fb0-423d-ff77-7efc0e9a41a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x * y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAESFwsGjrAh",
        "outputId": "c33daafc-f93c-43d6-b120-d09a7561293a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A=torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM_tqBi7j-ue",
        "outputId": "42dd679b-ba43-4416-c117-6dd3bd61463c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KlLB1Xsq6B6",
        "outputId": "846d28d8-adf3-4a19-b7e3-718005b2a873"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mv(A, x), A@x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiRIbfmAq9fv",
        "outputId": "b7c3dd95-a2eb-4d6f-9b96-45b9e2dd2ed6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8, 17, 26]), tensor([ 8, 17, 26]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B=torch.arange(6).reshape(3,2)\n",
        "B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmuxrcMzrHV5",
        "outputId": "eae3e2b4-581c-4d1b-f11a-6fd1035570dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mm(A, B), A@B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGdNl1LJrXnI",
        "outputId": "b1eb272c-2000-442a-8cf4-ec464835da50"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[16, 22],\n",
              "         [34, 49],\n",
              "         [52, 76]]),\n",
              " tensor([[16, 22],\n",
              "         [34, 49],\n",
              "         [52, 76]]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Norms"
      ],
      "metadata": {
        "id": "Xo_lE2HxrjFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = torch.tensor([4.0, -3.0])\n",
        "torch.norm(u)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDODy9MOra2H",
        "outputId": "104e07d7-3920-4baa-d773-e9b636841289"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manhattan distance"
      ],
      "metadata": {
        "id": "LUgwuzzRSQdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(u).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz7SM3_CR6Oh",
        "outputId": "21d93daf-9016-41e4-8baf-43252bc0ef57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "general form"
      ],
      "metadata": {
        "id": "qGyVkokFSsZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(torch.ones((4, 9)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUzQcBH0SUFF",
        "outputId": "4066a594-b549-478d-ca3a-5e3f7f2b9e93"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercises"
      ],
      "metadata": {
        "id": "J3LOXHcwS245"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "aj_1FhKtS-p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A=torch.arange(6).reshape(2,3)\n",
        "A.T.T==A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr4Tz5gySp-7",
        "outputId": "eb51abe7-c613-4c4a-b35e-3d2f3ec1e222"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2"
      ],
      "metadata": {
        "id": "BIBQDqbdTY_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A=torch.arange(6).reshape(2,3)\n",
        "B=torch.arange(6).reshape(2,3)\n",
        "A.T+B.T==(A+B).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT3jsaaLTZuL",
        "outputId": "26816015-f836-4c3d-d57d-fc924e3f0477"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True],\n",
              "        [True, True],\n",
              "        [True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "nsvICu3IT6H3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculus"
      ],
      "metadata": {
        "id": "iRkJS4zoUCWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib_inline import backend_inline\n"
      ],
      "metadata": {
        "id": "iNX8GGTlXYyb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0 \"wheel<0.40.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9Le_veu6UDF",
        "outputId": "a21f74c5-17e5-481d-fcf4-f0801ed763d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==65.5.0 in /usr/local/lib/python3.10/dist-packages (65.5.0)\n",
            "Requirement already satisfied: wheel<0.40.0 in /usr/local/lib/python3.10/dist-packages (0.38.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def f(x):\n",
        "  return x**2-3*x+1\n",
        "for h in 10.0**np.arange(-1, -6, -1):\n",
        "    print(f'h={h:.5f}, numerical limit={(f(1+h)-f(1))/h:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny83pLokYGen",
        "outputId": "eab3e793-add0-43c3-9778-b2a34a246c97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h=0.10000, numerical limit=-0.90000\n",
            "h=0.01000, numerical limit=-0.99000\n",
            "h=0.00100, numerical limit=-0.99900\n",
            "h=0.00010, numerical limit=-0.99990\n",
            "h=0.00001, numerical limit=-0.99999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "matplotlib"
      ],
      "metadata": {
        "id": "nf-XO_Pi2V9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def use_svg_display():\n",
        "    backend_inline.set_matplotlib_formats('svg')"
      ],
      "metadata": {
        "id": "MTZ-u9fzzYw1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_figsize(figsize=(3.5, 2.5)):\n",
        "    use_svg_display()\n",
        "    d2l.plt.rcParams['figure.figsize'] = figsize"
      ],
      "metadata": {
        "id": "Q9M2JQoS2Dtq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale), axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim),     axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()"
      ],
      "metadata": {
        "id": "jJwo7AEB2b4w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0 \"wheel<0.40.0\"\n",
        "!pip install d2l==1.0.0b0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhInS4rJ7hK7",
        "outputId": "b5e0cd2f-3a5d-49ed-a253-ebf09d986d95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==65.5.0 in /usr/local/lib/python3.10/dist-packages (65.5.0)\n",
            "Requirement already satisfied: wheel<0.40.0 in /usr/local/lib/python3.10/dist-packages (0.38.4)\n",
            "Requirement already satisfied: d2l==1.0.0b0 in /usr/local/lib/python3.10/dist-packages (1.0.0b0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (3.7.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (0.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.5.3)\n",
            "Requirement already satisfied: gym==0.21.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (0.21.0)\n",
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.11.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.21.0->d2l==1.0.0b0) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch->d2l==1.0.0b0) (1.2.2)\n",
            "Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch->d2l==1.0.0b0) (0.5.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (5.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline->d2l==1.0.0b0) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->d2l==1.0.0b0) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (2024.2.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2.2.1+cu121)\n",
            "Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (0.2.28)\n",
            "Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2.13.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->d2l==1.0.0b0) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->d2l==1.0.0b0) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->d2l==1.0.0b0) (3.0.10)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->d2l==1.0.0b0) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->d2l==1.0.0b0) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (3.1.3)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (5.10.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (1.0.0)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter->d2l==1.0.0b0) (2.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->d2l==1.0.0b0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->d2l==1.0.0b0) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (65.5.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->d2l==1.0.0b0) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l==1.0.0b0) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->d2l==1.0.0b0) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (12.4.99)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->d2l==1.0.0b0) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->d2l==1.0.0b0) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib_inline import backend_inline\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "-G93eiGo7nAG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3 * x ** 2 - 4 * x\n",
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=[], xlim=None,\n",
        "         ylim=None, xscale='linear', yscale='linear',\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
        "    \"\"\"Plot data points.\"\"\"\n",
        "\n",
        "    def has_one_axis(X):  # True if X (tensor or list) has 1 axis\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
        "                and not hasattr(X[0], \"__len__\"))\n",
        "\n",
        "    if has_one_axis(X): X = [X]\n",
        "    if Y is None:\n",
        "        X, Y = [[]] * len(X), X\n",
        "    elif has_one_axis(Y):\n",
        "        Y = [Y]\n",
        "    if len(X) != len(Y):\n",
        "        X = X * len(Y)\n",
        "\n",
        "    set_figsize(figsize)\n",
        "    if axes is None:\n",
        "        axes = d2l.plt.gca()\n",
        "    axes.cla()\n",
        "    for x, y, fmt in zip(X, Y, fmts):\n",
        "        axes.plot(x,y,fmt) if len(x) else axes.plot(y,fmt)\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "    x = np.arange(0, 3, 0.1)\n",
        "plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "VtiInt7p2rHe",
        "outputId": "b60e11f3-c9d4-4f3a-fb9c-9053baeeb7e1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"243.529359pt\" height=\"183.35625pt\" viewBox=\"0 0 243.529359 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-04-02T12:03:39.681345</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 183.35625 \nL 243.529359 183.35625 \nL 243.529359 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 145.8 \nL 235.903125 145.8 \nL 235.903125 7.2 \nL 40.603125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 49.480398 145.8 \nL 49.480398 7.2 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m3352d004d3\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3352d004d3\" x=\"49.480398\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(46.299148 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 110.702968 145.8 \nL 110.702968 7.2 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m3352d004d3\" x=\"110.702968\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(107.521718 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 171.925539 145.8 \nL 171.925539 7.2 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m3352d004d3\" x=\"171.925539\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2 -->\n      <g transform=\"translate(168.744289 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 233.148109 145.8 \nL 233.148109 7.2 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m3352d004d3\" x=\"233.148109\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3 -->\n      <g transform=\"translate(229.966859 160.398438) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- x -->\n     <g transform=\"translate(135.29375 174.076563) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \nL 2247 1797 \nL 3578 0 \nL 2900 0 \nL 1881 1375 \nL 863 0 \nL 184 0 \nL 1544 1831 \nL 300 3500 \nL 978 3500 \nL 1906 2253 \nL 2834 3500 \nL 3513 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path d=\"M 40.603125 116.769994 \nL 235.903125 116.769994 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"mc749f3c448\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc749f3c448\" x=\"40.603125\" y=\"116.769994\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(27.240625 120.569213) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path d=\"M 40.603125 78.886651 \nL 235.903125 78.886651 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mc749f3c448\" x=\"40.603125\" y=\"78.886651\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5 -->\n      <g transform=\"translate(27.240625 82.685869) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path d=\"M 40.603125 41.003307 \nL 235.903125 41.003307 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mc749f3c448\" x=\"40.603125\" y=\"41.003307\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 44.802526) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_9\">\n     <!-- f(x) -->\n     <g transform=\"translate(14.798437 85.121094) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"35.205078\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"74.21875\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"133.398438\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 49.480398 116.769994 \nL 55.602655 119.573361 \nL 61.724912 121.922129 \nL 67.847169 123.816296 \nL 73.969426 125.255863 \nL 80.091683 126.24083 \nL 86.21394 126.771197 \nL 92.336197 126.846963 \nL 98.458454 126.46813 \nL 104.580711 125.634696 \nL 110.702968 124.346663 \nL 116.825225 122.604029 \nL 122.947482 120.406795 \nL 129.069739 117.754961 \nL 135.191996 114.648527 \nL 141.314254 111.087492 \nL 147.436511 107.071858 \nL 153.558768 102.601624 \nL 159.681025 97.676789 \nL 165.803282 92.297354 \nL 171.925539 86.463319 \nL 178.047796 80.174684 \nL 184.170053 73.431449 \nL 190.29231 66.233614 \nL 196.414567 58.581179 \nL 202.536824 50.474143 \nL 208.659081 41.912508 \nL 214.781338 32.896272 \nL 220.903595 23.425436 \nL 227.025852 13.5 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 49.480398 139.5 \nL 55.602655 137.984666 \nL 61.724912 136.469333 \nL 67.847169 134.953999 \nL 73.969426 133.438665 \nL 80.091683 131.923331 \nL 86.21394 130.407998 \nL 92.336197 128.892664 \nL 98.458454 127.37733 \nL 104.580711 125.861996 \nL 110.702968 124.346663 \nL 116.825225 122.831329 \nL 122.947482 121.315995 \nL 129.069739 119.800661 \nL 135.191996 118.285328 \nL 141.314254 116.769994 \nL 147.436511 115.25466 \nL 153.558768 113.739327 \nL 159.681025 112.223993 \nL 165.803282 110.708659 \nL 171.925539 109.193325 \nL 178.047796 107.677992 \nL 184.170053 106.162658 \nL 190.29231 104.647324 \nL 196.414567 103.13199 \nL 202.536824 101.616657 \nL 208.659081 100.101323 \nL 214.781338 98.585989 \nL 220.903595 97.070655 \nL 227.025852 95.555322 \n\" clip-path=\"url(#p7fe9bfd799)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 145.8 \nL 40.603125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 235.903125 145.8 \nL 235.903125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 145.8 \nL 235.903125 145.8 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 7.2 \nL 235.903125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 47.603125 44.55625 \nL 172.153125 44.55625 \nQ 174.153125 44.55625 174.153125 42.55625 \nL 174.153125 14.2 \nQ 174.153125 12.2 172.153125 12.2 \nL 47.603125 12.2 \nQ 45.603125 12.2 45.603125 14.2 \nL 45.603125 42.55625 \nQ 45.603125 44.55625 47.603125 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 49.603125 20.298438 \nL 59.603125 20.298438 \nL 69.603125 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_10\">\n     <!-- f(x) -->\n     <g transform=\"translate(77.603125 23.798438) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-66\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"35.205078\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"74.21875\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"133.398438\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 49.603125 34.976562 \nL 59.603125 34.976562 \nL 69.603125 34.976562 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- Tangent line (x=1) -->\n     <g transform=\"translate(77.603125 38.476562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"44.583984\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"105.863281\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"169.242188\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"232.71875\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"294.242188\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"357.621094\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"396.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"428.617188\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"456.400391\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"484.183594\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"547.5625\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"609.085938\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"640.873047\"/>\n      <use xlink:href=\"#DejaVuSans-78\" x=\"679.886719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"739.066406\"/>\n      <use xlink:href=\"#DejaVuSans-31\" x=\"822.855469\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"886.478516\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7fe9bfd799\">\n   <rect x=\"40.603125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Automatic Differentiation"
      ],
      "metadata": {
        "id": "XxQItijb44OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "UummX5DB5BoL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4.0)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11E5jkNc5Vgf",
        "outputId": "4411a553-57f7-4686-f616-99119b4a75ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "x.grad"
      ],
      "metadata": {
        "id": "WTckW0V__y5G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf25zVGiL47o",
        "outputId": "d3436cd4-5b98-47d1-9fec-14560c63c5e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWkCjOGGVdzW",
        "outputId": "62f34c5f-c6cd-409e-d399-ad01de383030"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad == 4 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuJg01l_X_i9",
        "outputId": "4213f6e3-98c4-4915-b50e-21dd48b7dffd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()  # Reset the gradient\n",
        "y = x.sum()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcAdmc-1Yu8v",
        "outputId": "73282188-2c38-4553-df3d-8536b57c882c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7AvQq06ZR0W",
        "outputId": "5e419c54-ace8-4167-bd48-e859235dc858"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "y.backward(gradient=torch.ones(len(y)))  # Faster: y.sum().backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "851ipvMMZ5tE",
        "outputId": "2c9cc67a-f5a0-43bb-b116-eeb1f5c58c5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKwtz1yuZ5wa",
        "outputId": "bbb567c4-968d-4687-9b77-84d47507acac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l770W9Nnfvje",
        "outputId": "049517c1-7057-44a6-95fb-eaa64abdc0a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Control Flow in python"
      ],
      "metadata": {
        "id": "L-_PJerVgGh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "metadata": {
        "id": "_1YEQGgGf1fS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ],
      "metadata": {
        "id": "wZ716XezgXXn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad == d / a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgKIaJhngbEj",
        "outputId": "6983f51f-dda2-4917-bb82-9b2b620c822a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Probability and Statistics"
      ],
      "metadata": {
        "id": "JDbYuy_3hHwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==65.5.0 \"wheel<0.40.0\"\n",
        "!pip install d2l==1.0.0b0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYsPoccwhR8l",
        "outputId": "e072335a-3220-42f4-d5ba-c7c350a1c7fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==65.5.0 in /usr/local/lib/python3.10/dist-packages (65.5.0)\n",
            "Requirement already satisfied: wheel<0.40.0 in /usr/local/lib/python3.10/dist-packages (0.38.4)\n",
            "Collecting d2l==1.0.0b0\n",
            "  Using cached d2l-1.0.0b0-py3-none-any.whl (141 kB)\n",
            "Collecting jupyter (from d2l==1.0.0b0)\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (3.7.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (0.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.5.3)\n",
            "Collecting gym==0.21.0 (from d2l==1.0.0b0)\n",
            "  Using cached gym-0.21.0.tar.gz (1.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gpytorch (from d2l==1.0.0b0)\n",
            "  Using cached gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.0b0) (1.11.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.21.0->d2l==1.0.0b0) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch->d2l==1.0.0b0) (1.2.2)\n",
            "Collecting linear-operator>=0.5.0 (from gpytorch->d2l==1.0.0b0)\n",
            "  Using cached linear_operator-0.5.2-py3-none-any.whl (175 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (6.5.5)\n",
            "Collecting qtconsole (from jupyter->d2l==1.0.0b0)\n",
            "  Using cached qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->d2l==1.0.0b0) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->d2l==1.0.0b0) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline->d2l==1.0.0b0) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->d2l==1.0.0b0) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->d2l==1.0.0b0) (2024.2.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2.2.1+cu121)\n",
            "Collecting jaxtyping>=0.2.9 (from linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Using cached jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->d2l==1.0.0b0) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter->d2l==1.0.0b0) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->d2l==1.0.0b0) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->d2l==1.0.0b0) (3.0.10)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->d2l==1.0.0b0) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter->d2l==1.0.0b0) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (3.1.3)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (5.10.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->d2l==1.0.0b0) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->d2l==1.0.0b0) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->d2l==1.0.0b0)\n",
            "  Using cached QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->d2l==1.0.0b0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->d2l==1.0.0b0) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (65.5.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->d2l==1.0.0b0) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->d2l==1.0.0b0) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter->d2l==1.0.0b0) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cublas-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter->d2l==1.0.0b0) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter->d2l==1.0.0b0) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0b0) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->d2l==1.0.0b0) (0.18.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch->d2l==1.0.0b0) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->d2l==1.0.0b0) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->d2l==1.0.0b0) (2.21)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616798 sha256=639d27699b240a4bb1d081bce0dbeae8b27c9fa7003a24bf09bdb40a8e138137\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/aa/90/b67df76370d3916a2189b662cf48da38ce41a4e7e58b6abff5\n",
            "Successfully built gym\n",
            "Installing collected packages: typeguard, qtpy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, gym, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, qtconsole, linear-operator, gpytorch, jupyter, d2l\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed d2l-1.0.0b0 gpytorch-1.11 gym-0.21.0 jaxtyping-0.2.28 jedi-0.19.1 jupyter-1.0.0 linear-operator-0.5.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 qtconsole-5.5.1 qtpy-2.4.1 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "g7ZcMGwQhKKO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ7br6iIjZcy",
        "outputId": "f40e90b3-b124-44cb-9ab2-fa89ba36067a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [55, 45]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_UljZEKj_1G",
        "outputId": "569eac2a-f5e0-4f0b-af3d-d1316a1663db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([52., 48.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYEaorEekW6a",
        "outputId": "a3e75de6-63d3-48fe-9976-c8bd65f52bee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4600, 0.5400])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qylMRO6tneNy",
        "outputId": "7e22a9de-09f1-494c-9f36-a351f54b697b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5004, 0.4996])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "d2l.set_figsize((4.5, 3.5))\n",
        "d2l.plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "d2l.plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Samples')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "XVEzIGpznqWq",
        "outputId": "345d7a12-aa97-425b-f209-08e48b9761e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"238.79625pt\" viewBox=\"0 0 306.596693 238.79625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-04-02T15:15:40.060941</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 238.79625 \nL 306.596693 238.79625 \nL 306.596693 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mad28f541cf\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mad28f541cf\" x=\"55.194886\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.013636 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mad28f541cf\" x=\"100.853998\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(88.128998 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#mad28f541cf\" x=\"146.513109\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(133.788109 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mad28f541cf\" x=\"192.17222\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(179.44722 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mad28f541cf\" x=\"237.831332\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(225.106332 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mad28f541cf\" x=\"283.490443\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(267.584193 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Samples -->\n     <g transform=\"translate(147.978125 229.516562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m23581f73a8\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m23581f73a8\" x=\"43.78125\" y=\"192.42\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 196.219219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m23581f73a8\" x=\"43.78125\" y=\"157.14\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 160.939219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m23581f73a8\" x=\"43.78125\" y=\"121.86\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 125.659219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m23581f73a8\" x=\"43.78125\" y=\"86.58\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 90.379219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m23581f73a8\" x=\"43.78125\" y=\"51.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 55.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m23581f73a8\" x=\"43.78125\" y=\"16.02\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 19.819219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Estimated probability -->\n     <g transform=\"translate(14.798438 157.743437) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 55.194886 192.42 \nL 55.217716 192.42 \nL 55.354693 104.22 \nL 55.400352 121.859999 \nL 55.491671 116.819999 \nL 55.651477 133.619998 \nL 55.834114 113.344138 \nL 55.856943 115.979999 \nL 55.902603 109.7325 \nL 55.971091 101.699995 \nL 56.03958 104.22 \nL 56.062409 106.481538 \nL 56.108069 102.068783 \nL 56.130898 104.22 \nL 56.336364 95.572936 \nL 56.496171 104.22 \nL 56.519001 102.725083 \nL 56.587489 98.529672 \nL 56.633148 101.46375 \nL 56.655978 102.863072 \nL 56.701637 100.27075 \nL 56.770126 96.659995 \nL 56.815785 99.319998 \nL 56.975592 103.103543 \nL 57.203887 95.300901 \nL 57.226717 96.38 \nL 57.432183 92.638186 \nL 57.59199 95.899246 \nL 57.683308 94.59818 \nL 57.637649 96.053333 \nL 57.728967 94.770005 \nL 57.820285 98.137238 \nL 57.888774 97.549407 \nL 57.957263 95.54459 \nL 58.048581 95.820001 \nL 58.276876 100.32882 \nL 58.299706 99.713431 \nL 58.368195 100.439998 \nL 58.391024 101.092344 \nL 58.436683 99.902519 \nL 58.528001 100.019995 \nL 58.573661 98.892488 \nL 58.642149 98.41737 \nL 58.687808 99.63818 \nL 58.733467 98.566157 \nL 58.779127 99.754173 \nL 58.801956 100.336979 \nL 58.847615 99.289569 \nL 58.916104 97.766337 \nL 58.961763 98.906745 \nL 58.984593 99.466703 \nL 59.030252 98.479172 \nL 59.12157 97.592253 \nL 59.075911 98.546316 \nL 59.167229 97.667997 \nL 59.486843 102.819995 \nL 59.64665 100.620002 \nL 59.532502 102.834662 \nL 59.669479 101.085994 \nL 59.692309 101.547275 \nL 59.737968 100.692003 \nL 59.760798 101.148354 \nL 59.852116 101.208296 \nL 59.920604 99.97962 \nL 60.034752 100.493242 \nL 60.057582 100.098505 \nL 60.103241 100.953335 \nL 60.12607 100.561931 \nL 60.263048 101.451385 \nL 60.285877 101.070002 \nL 60.331536 101.878411 \nL 60.377196 101.125264 \nL 60.400025 101.523934 \nL 60.445684 100.783635 \nL 60.468514 101.178624 \nL 60.537002 101.59277 \nL 60.628321 100.160581 \nL 60.810957 101.720403 \nL 60.833787 101.374841 \nL 60.879446 102.103196 \nL 61.039253 103.190433 \nL 61.130571 101.854481 \nL 61.17623 102.543196 \nL 61.313207 103.236359 \nL 61.358866 102.592698 \nL 61.404526 103.250764 \nL 61.450185 102.616365 \nL 61.495844 103.264769 \nL 61.541503 102.63936 \nL 61.564332 102.329999 \nL 61.609992 102.96894 \nL 61.724139 103.912679 \nL 61.746969 103.607502 \nL 61.792628 103.003448 \nL 61.861117 103.31693 \nL 61.998094 104.514983 \nL 62.020924 104.22 \nL 62.135071 103.352458 \nL 62.157901 103.643524 \nL 62.22639 103.934559 \nL 62.249219 103.650968 \nL 62.523174 101.480867 \nL 62.546003 101.762418 \nL 62.591662 101.23477 \nL 62.614492 101.514481 \nL 62.637322 101.253023 \nL 62.70581 101.547275 \nL 62.865617 102.387953 \nL 62.979765 101.641052 \nL 62.911276 102.398762 \nL 63.002594 101.905717 \nL 63.071083 102.690522 \nL 63.116742 102.192409 \nL 63.139572 101.945503 \nL 63.185231 102.461027 \nL 63.20806 102.215456 \nL 63.23089 102.470995 \nL 63.276549 101.983943 \nL 63.299379 102.237978 \nL 63.322208 101.996465 \nL 63.390697 102.259995 \nL 63.550504 103.979676 \nL 63.618992 103.743241 \nL 63.641822 103.506797 \nL 63.687481 103.983534 \nL 63.710311 103.748341 \nL 63.870118 104.451498 \nL 63.938606 104.22 \nL 63.961436 104.44909 \nL 64.052754 105.353674 \nL 64.098413 104.896724 \nL 64.25822 104.22 \nL 64.372368 104.43886 \nL 64.395197 104.22 \nL 64.440856 104.654481 \nL 64.577834 105.93262 \nL 64.623493 105.498261 \nL 64.806129 104.63801 \nL 64.828959 104.84553 \nL 64.874618 104.42753 \nL 64.897448 104.634083 \nL 65.125743 103.410823 \nL 65.171402 103.817262 \nL 65.239891 103.620004 \nL 65.30838 103.822698 \nL 65.354039 103.42897 \nL 65.376868 103.628058 \nL 65.422527 103.237821 \nL 65.445357 103.436004 \nL 65.468186 103.242174 \nL 65.513846 103.635891 \nL 65.719312 104.60182 \nL 65.993266 103.103543 \nL 66.084584 103.48192 \nL 66.107414 103.299329 \nL 66.175903 103.122069 \nL 66.198732 103.306952 \nL 66.31288 103.85852 \nL 66.33571 103.678894 \nL 66.358539 103.500005 \nL 66.404198 103.861464 \nL 66.564005 104.396755 \nL 66.609664 104.043949 \nL 66.678153 104.22 \nL 66.700982 104.394652 \nL 66.746642 104.046031 \nL 66.769471 104.22 \nL 66.883619 104.048071 \nL 67.134744 105.566566 \nL 67.157574 105.395999 \nL 67.34021 104.385479 \nL 67.36304 104.550337 \nL 67.431528 104.712735 \nL 67.454358 104.547882 \nL 67.522846 104.709092 \nL 67.591335 104.22 \nL 67.728312 104.540727 \nL 67.751142 104.380074 \nL 67.796801 104.698483 \nL 67.819631 104.538414 \nL 67.888119 105.011739 \nL 67.956608 104.849999 \nL 68.093585 104.22 \nL 68.116415 104.375553 \nL 68.34471 105.290015 \nL 68.413199 105.132412 \nL 68.436029 105.28265 \nL 68.458858 105.432373 \nL 68.504517 105.126166 \nL 68.550176 104.822046 \nL 68.595836 105.12 \nL 68.801302 105.845126 \nL 68.938279 105.536417 \nL 68.983938 105.823635 \nL 69.029597 105.527743 \nL 69.280722 104.505436 \nL 69.303552 104.647462 \nL 69.349211 104.362027 \nL 69.486188 104.07933 \nL 69.600336 104.499112 \nL 69.623166 104.359335 \nL 69.805802 103.80721 \nL 69.965609 104.22 \nL 69.988438 104.084103 \nL 70.034098 104.355481 \nL 70.171075 104.89123 \nL 70.193904 104.756169 \nL 70.262393 104.620304 \nL 70.285223 104.752931 \nL 70.308052 104.885158 \nL 70.353711 104.617896 \nL 70.513518 103.957501 \nL 70.536348 104.08895 \nL 70.627666 104.350282 \nL 70.650496 104.22 \nL 70.810302 103.833727 \nL 70.855962 104.091621 \nL 70.92445 103.964346 \nL 71.084257 103.587283 \nL 71.152746 103.968005 \nL 71.221234 103.843611 \nL 71.403871 103.351648 \nL 71.563678 103.728637 \nL 71.586507 103.606651 \nL 71.632166 103.85301 \nL 71.837632 104.703288 \nL 71.860462 104.581969 \nL 71.997439 104.100327 \nL 72.020269 104.22 \nL 72.225735 105.046505 \nL 72.248564 104.927489 \nL 72.317053 104.807216 \nL 72.339883 104.923725 \nL 72.362712 105.039918 \nL 72.408371 104.804104 \nL 72.47686 104.685435 \nL 72.49969 104.801028 \nL 72.522519 104.916317 \nL 72.568178 104.68299 \nL 72.591008 104.797979 \nL 72.659496 104.91086 \nL 72.705156 104.679373 \nL 72.819303 105.018705 \nL 72.842133 104.903721 \nL 72.887792 104.674637 \nL 72.933451 104.900204 \nL 73.047599 105.233795 \nL 73.070428 105.12 \nL 73.207406 104.889874 \nL 73.48136 105.75965 \nL 73.686826 104.981285 \nL 73.709656 105.088967 \nL 73.892292 105.51073 \nL 73.960781 105.398859 \nL 73.983611 105.504464 \nL 74.00644 105.609817 \nL 74.052099 105.393155 \nL 74.074929 105.285215 \nL 74.120588 105.49518 \nL 74.143418 105.387509 \nL 74.348884 105.9 \nL 74.440202 105.683033 \nL 74.463031 105.785678 \nL 74.53152 105.67613 \nL 74.600009 105.981927 \nL 74.622838 105.876338 \nL 74.668497 106.079016 \nL 74.691327 105.973684 \nL 74.828304 106.371217 \nL 74.851134 106.266406 \nL 75.03377 105.639309 \nL 75.0566 105.738942 \nL 75.239236 106.126482 \nL 75.262066 106.024089 \nL 75.307725 106.220001 \nL 75.353384 106.415025 \nL 75.399043 106.21097 \nL 75.421873 106.109291 \nL 75.467532 106.303464 \nL 75.55885 106.689205 \nL 75.604509 106.48659 \nL 75.741486 106.079936 \nL 75.764316 106.175652 \nL 75.832805 106.266632 \nL 75.855634 106.16702 \nL 75.878464 106.067629 \nL 75.924123 106.257621 \nL 75.946952 106.158461 \nL 75.969782 106.253153 \nL 76.015441 106.05549 \nL 76.220907 105.559264 \nL 76.449203 106.112703 \nL 76.472032 106.01614 \nL 76.517691 106.20096 \nL 76.745987 106.74 \nL 76.814476 106.825065 \nL 76.860135 106.633895 \nL 76.997112 106.987784 \nL 77.019942 106.892725 \nL 77.065601 106.70321 \nL 77.11126 106.881601 \nL 77.179748 106.781826 \nL 77.248237 107.047505 \nL 77.430874 106.662462 \nL 77.59068 106.9145 \nL 77.704828 106.811492 \nL 77.773317 106.714545 \nL 77.818976 106.887336 \nL 77.887465 106.790652 \nL 77.910294 106.876627 \nL 77.955953 107.048057 \nL 78.001612 106.865997 \nL 78.184249 106.495002 \nL 78.366885 106.824329 \nL 78.549522 106.459453 \nL 78.732158 106.783955 \nL 78.800647 106.520872 \nL 78.869136 106.599193 \nL 78.937624 106.677061 \nL 78.960454 106.590056 \nL 78.983283 106.503224 \nL 79.028942 106.667656 \nL 79.051772 106.580993 \nL 79.257238 106.978863 \nL 79.280068 106.892725 \nL 79.325727 107.054402 \nL 79.348556 106.968443 \nL 79.462704 107.20421 \nL 79.485534 107.118592 \nL 79.599681 107.022618 \nL 79.736659 107.498809 \nL 79.782318 107.329093 \nL 79.805147 107.244469 \nL 79.850807 107.402051 \nL 80.079102 107.857944 \nL 80.216079 107.516446 \nL 80.238909 107.593768 \nL 80.375886 107.895002 \nL 80.398716 107.811855 \nL 80.467205 107.881733 \nL 80.512864 107.716217 \nL 80.581352 107.786037 \nL 80.604182 107.703663 \nL 80.786818 107.364384 \nL 80.832477 107.515731 \nL 80.878137 107.353212 \nL 80.969455 107.02991 \nL 81.037943 107.100318 \nL 81.152091 107.320177 \nL 81.174921 107.240016 \nL 81.19775 107.160002 \nL 81.243409 107.309315 \nL 81.266239 107.383777 \nL 81.311898 107.224192 \nL 81.448875 106.748758 \nL 81.494535 106.897362 \nL 81.517364 106.971471 \nL 81.563023 106.81412 \nL 81.768489 106.415535 \nL 81.836978 106.485413 \nL 81.859807 106.408023 \nL 81.882637 106.330769 \nL 81.928296 106.47768 \nL 81.951126 106.400563 \nL 82.088103 106.539083 \nL 82.156592 106.45858 \nL 82.179421 106.531244 \nL 82.24791 106.451031 \nL 82.293569 106.59576 \nL 82.362058 106.51572 \nL 82.384887 106.587785 \nL 82.453376 106.655649 \nL 82.476205 106.579868 \nL 82.636012 106.346183 \nL 82.841478 106.839801 \nL 82.864308 106.764929 \nL 82.909967 106.615553 \nL 82.955626 106.756565 \nL 83.138263 107.028001 \nL 83.298069 106.654093 \nL 83.320899 106.72365 \nL 83.480706 106.922901 \nL 83.594854 106.69952 \nL 83.617683 106.768315 \nL 83.77749 106.965252 \nL 83.845979 107.028916 \nL 83.914467 106.812059 \nL 83.937297 106.880002 \nL 83.982956 106.736004 \nL 84.005786 106.803848 \nL 84.188422 106.510006 \nL 84.234081 106.644982 \nL 84.27974 106.502824 \nL 84.530865 106.003203 \nL 84.667843 106.267988 \nL 84.690672 106.19819 \nL 84.736331 106.058918 \nL 84.80482 106.122618 \nL 85.010286 106.716863 \nL 85.055945 106.578291 \nL 85.261411 106.227587 \nL 85.581025 106.868647 \nL 85.649514 106.79663 \nL 85.672343 106.860719 \nL 85.786491 107.179732 \nL 85.83215 107.043978 \nL 85.991957 106.702669 \nL 86.014787 106.766112 \nL 86.151764 106.88485 \nL 86.197423 106.751124 \nL 86.243082 106.877016 \nL 86.288741 107.002541 \nL 86.35723 106.931859 \nL 86.380059 106.865356 \nL 86.425719 106.990344 \nL 86.517037 107.110748 \nL 86.539866 107.044456 \nL 86.562696 106.978253 \nL 86.608355 107.102353 \nL 86.631185 107.036255 \nL 86.699673 106.966272 \nL 86.790991 107.213068 \nL 86.905139 107.011941 \nL 86.927969 107.073344 \nL 86.950798 107.134653 \nL 86.996457 107.003929 \nL 87.156264 106.801156 \nL 87.201923 106.923206 \nL 87.247583 106.793807 \nL 87.316071 106.725679 \nL 87.338901 106.786499 \nL 87.430219 106.904075 \nL 87.453049 106.839801 \nL 87.498708 106.711527 \nL 87.544367 106.83241 \nL 87.818321 107.303916 \nL 87.863981 107.176426 \nL 87.932469 107.23171 \nL 88.046617 107.527502 \nL 88.092276 107.400584 \nL 88.137935 107.274019 \nL 88.183594 107.391784 \nL 88.320572 107.500165 \nL 88.503208 107.240547 \nL 88.571697 107.294643 \nL 88.594526 107.232293 \nL 88.685845 107.103925 \nL 88.708674 107.162 \nL 88.731504 107.220002 \nL 88.777163 107.096086 \nL 89.005458 106.719597 \nL 89.051117 106.835096 \nL 89.119606 106.770507 \nL 89.142436 106.709514 \nL 89.188095 106.824566 \nL 89.302243 106.87485 \nL 89.530538 106.505579 \nL 89.576197 106.619601 \nL 89.621856 106.499523 \nL 89.713175 106.376906 \nL 89.736004 106.433741 \nL 89.918641 106.653904 \nL 89.987129 106.591281 \nL 90.009959 106.647522 \nL 90.055618 106.759793 \nL 90.101277 106.641176 \nL 90.124107 106.581986 \nL 90.169766 106.693974 \nL 90.283913 106.85797 \nL 90.306743 106.798948 \nL 90.420891 106.73347 \nL 90.44372 106.788933 \nL 90.489379 106.671584 \nL 90.512209 106.726978 \nL 90.535039 106.668419 \nL 90.580698 106.778992 \nL 90.603527 106.720517 \nL 90.672016 106.658972 \nL 90.717675 106.769135 \nL 90.923141 106.472875 \nL 91.014459 106.579489 \nL 91.037289 106.521845 \nL 91.174266 106.289374 \nL 91.197096 106.343954 \nL 91.379732 106.555685 \nL 91.653687 106.096596 \nL 91.722175 106.148168 \nL 91.745005 106.091911 \nL 91.927641 105.863479 \nL 92.224426 106.448098 \nL 92.247255 106.392414 \nL 92.338573 106.278724 \nL 92.361403 106.3316 \nL 92.429892 106.273677 \nL 92.49838 106.431743 \nL 92.703846 106.151385 \nL 92.772335 106.094319 \nL 92.863653 106.303464 \nL 93.02346 106.135078 \nL 93.137608 106.182355 \nL 93.320244 105.961829 \nL 93.411563 106.062987 \nL 93.434392 106.009259 \nL 93.502881 105.84847 \nL 93.54854 105.951467 \nL 93.617029 105.89601 \nL 93.685517 106.049875 \nL 93.822495 105.939197 \nL 93.868154 106.041238 \nL 93.913813 105.935144 \nL 93.959472 105.829302 \nL 94.005131 105.931112 \nL 94.027961 105.981927 \nL 94.07362 105.876338 \nL 94.187767 105.613444 \nL 94.256256 105.662525 \nL 94.324745 105.608571 \nL 94.370404 105.709692 \nL 94.393233 105.657483 \nL 94.438893 105.758373 \nL 94.484552 105.859026 \nL 94.530211 105.754803 \nL 94.644359 105.699351 \nL 94.667188 105.749478 \nL 94.712847 105.645865 \nL 94.781336 105.694236 \nL 94.918313 105.38519 \nL 95.009631 105.483609 \nL 95.032461 105.432373 \nL 95.055291 105.38119 \nL 95.10095 105.480723 \nL 95.169438 105.629589 \nL 95.237927 105.576923 \nL 95.260757 105.525924 \nL 95.306416 105.624779 \nL 95.352075 105.723408 \nL 95.420563 105.670821 \nL 95.671689 105.313798 \nL 95.694518 105.362874 \nL 95.740177 105.262321 \nL 95.808666 105.111909 \nL 95.877155 105.159875 \nL 96.10545 105.548166 \nL 96.12828 105.498261 \nL 96.173939 105.398617 \nL 96.219598 105.495416 \nL 96.356575 105.784522 \nL 96.425064 105.733118 \nL 96.6077 105.532064 \nL 96.699019 105.723134 \nL 96.744678 105.62461 \nL 96.904485 105.377988 \nL 96.927314 105.425575 \nL 97.13278 105.659607 \nL 97.15561 105.610863 \nL 97.201269 105.705171 \nL 97.269757 105.654923 \nL 97.315417 105.748926 \nL 97.429564 105.601847 \nL 97.452394 105.648725 \nL 97.63503 105.832257 \nL 97.726349 105.734164 \nL 97.749178 105.780642 \nL 98.091621 106.284254 \nL 98.205769 106.231988 \nL 98.251428 106.323341 \nL 98.297087 106.227729 \nL 98.456894 106.080761 \nL 98.571042 106.122261 \nL 98.593872 106.074889 \nL 98.639531 106.16559 \nL 98.66236 106.118265 \nL 98.799338 106.296924 \nL 98.822167 106.249709 \nL 98.913485 106.153404 \nL 98.936315 106.198405 \nL 98.959145 106.243359 \nL 99.004804 106.149377 \nL 99.027633 106.102457 \nL 99.073292 106.192233 \nL 99.164611 106.27968 \nL 99.18744 106.232866 \nL 99.278758 106.137391 \nL 99.301588 106.182029 \nL 99.347247 106.271164 \nL 99.415736 106.222477 \nL 99.644031 105.940532 \nL 99.666861 105.984903 \nL 99.71252 105.892682 \nL 99.872327 105.751565 \nL 99.895156 105.795804 \nL 99.940816 105.70424 \nL 100.146282 105.473605 \nL 100.351748 105.690745 \nL 100.420236 105.644014 \nL 100.443066 105.687775 \nL 100.71702 106.032632 \nL 100.73985 105.987536 \nL 100.785509 106.074053 \nL 101.013805 106.328367 \nL 101.127952 106.279312 \nL 101.173612 106.364814 \nL 101.2421 106.317921 \nL 101.26493 106.273193 \nL 101.310589 106.358448 \nL 101.333418 106.40101 \nL 101.379078 106.311701 \nL 101.401907 106.354221 \nL 101.424737 106.309635 \nL 101.470396 106.394554 \nL 101.538884 106.434771 \nL 101.561714 106.390275 \nL 101.653032 106.299374 \nL 101.675862 106.341651 \nL 101.858498 106.592127 \nL 101.881328 106.547857 \nL 101.949816 106.415314 \nL 102.018305 106.45509 \nL 102.200942 106.7033 \nL 102.223771 106.659303 \nL 102.315089 106.483731 \nL 102.360748 106.566877 \nL 102.452067 106.647522 \nL 102.474896 106.603782 \nL 102.680362 106.296792 \nL 102.703192 106.338155 \nL 102.77168 106.292807 \nL 102.81734 106.375344 \nL 102.840169 106.332068 \nL 102.885828 106.414452 \nL 102.908658 106.371217 \nL 102.931487 106.412349 \nL 102.977146 106.326017 \nL 103.022806 106.239847 \nL 103.091294 106.278981 \nL 103.159783 106.401924 \nL 103.205442 106.316007 \nL 103.31959 106.269219 \nL 103.388078 106.308069 \nL 103.410908 106.265339 \nL 103.433738 106.222651 \nL 103.479397 106.304121 \nL 103.547885 106.342792 \nL 103.570715 106.300188 \nL 103.593544 106.257621 \nL 103.639204 106.338797 \nL 103.753351 106.375265 \nL 103.867499 106.246161 \nL 103.890329 106.286541 \nL 104.164283 106.603782 \nL 104.187113 106.561594 \nL 104.232772 106.641497 \nL 104.278431 106.721253 \nL 104.34692 106.676825 \nL 104.369749 106.634757 \nL 104.415408 106.714298 \nL 104.438238 106.672272 \nL 104.529556 106.749326 \nL 104.552386 106.707379 \nL 104.666534 106.579594 \nL 104.689363 106.61917 \nL 104.872 106.934472 \nL 104.940488 106.890275 \nL 104.986147 106.806986 \nL 105.031806 106.885386 \nL 105.123125 106.961136 \nL 105.145954 106.919589 \nL 105.328591 106.749174 \nL 105.511227 106.900001 \nL 105.579716 106.776521 \nL 105.625375 106.854027 \nL 105.808011 107.003587 \nL 105.89933 106.998577 \nL 105.922159 107.037007 \nL 105.967818 106.95519 \nL 106.218943 106.665617 \nL 106.355921 106.73775 \nL 106.424409 106.616526 \nL 106.470068 106.692896 \nL 106.675534 106.956704 \nL 106.698364 106.916413 \nL 106.766853 106.795752 \nL 106.812512 106.87146 \nL 107.017978 107.055138 \nL 107.040807 107.015069 \nL 107.086466 107.090183 \nL 107.109296 107.127692 \nL 107.154955 107.047668 \nL 107.223444 107.005264 \nL 107.246273 107.042711 \nL 107.42891 107.186972 \nL 107.588717 107.062682 \nL 107.611546 107.099845 \nL 107.657205 107.02061 \nL 107.839842 106.85797 \nL 107.95399 106.890417 \nL 108.068137 106.846588 \nL 108.227944 107.028432 \nL 108.250774 106.989293 \nL 108.319262 106.947835 \nL 108.342092 106.984535 \nL 108.43341 106.979793 \nL 108.547558 106.93617 \nL 108.593217 107.009233 \nL 108.638876 106.931528 \nL 108.661706 106.892725 \nL 108.707365 106.965673 \nL 108.912831 107.142517 \nL 109.026979 107.09893 \nL 109.141126 107.130152 \nL 109.163956 107.091628 \nL 109.209615 107.163725 \nL 109.346592 107.230621 \nL 109.529229 107.072329 \nL 109.643377 107.10332 \nL 109.803184 106.910599 \nL 109.826013 106.946316 \nL 109.894502 106.979699 \nL 109.917331 106.941768 \nL 110.00865 106.790358 \nL 110.054309 106.861597 \nL 110.259775 107.034504 \nL 110.328263 106.994503 \nL 110.351093 107.029846 \nL 110.419582 107.062809 \nL 110.442411 107.025204 \nL 110.533729 106.947835 \nL 110.556559 106.983068 \nL 110.739195 107.118934 \nL 110.807684 107.006789 \nL 110.853343 107.076824 \nL 110.921832 107.109434 \nL 110.944661 107.072151 \nL 111.058809 107.030293 \nL 111.150127 107.097653 \nL 111.172957 107.060522 \nL 111.355593 106.907934 \nL 111.469741 107.00978 \nL 111.492571 106.972896 \nL 111.5154 106.936043 \nL 111.561059 107.005264 \nL 111.583889 107.03983 \nL 111.629548 106.966219 \nL 111.766525 106.817259 \nL 111.789355 106.851772 \nL 111.949162 107.021687 \nL 111.971991 106.985114 \nL 112.108969 106.907729 \nL 112.154628 106.97625 \nL 112.200287 106.903428 \nL 112.337264 106.826548 \nL 112.519901 106.958696 \nL 112.656878 106.882111 \nL 112.702537 106.950001 \nL 112.748196 106.877889 \nL 112.885174 106.801803 \nL 112.908003 106.835659 \nL 112.953662 106.763894 \nL 113.113469 106.652626 \nL 113.227617 106.682524 \nL 113.341765 106.643079 \nL 113.547231 106.807018 \nL 113.59289 106.736062 \nL 113.638549 106.802975 \nL 113.798356 106.89897 \nL 113.889674 106.757638 \nL 113.935333 106.824198 \nL 114.09514 106.919652 \nL 114.414754 106.5652 \nL 114.460413 106.631319 \nL 114.506072 106.561594 \nL 114.574561 106.457203 \nL 114.62022 106.523227 \nL 114.780027 106.685951 \nL 114.802856 106.651238 \nL 114.917004 106.612893 \nL 115.053981 106.674669 \nL 115.259447 106.431701 \nL 115.282277 106.464358 \nL 115.487743 106.690399 \nL 115.510572 106.656096 \nL 115.693209 106.515662 \nL 115.784527 106.512203 \nL 115.898675 106.408422 \nL 115.944334 106.473043 \nL 116.058482 106.501889 \nL 116.241118 106.363179 \nL 116.263948 106.395337 \nL 116.355266 106.457913 \nL 116.378096 106.424178 \nL 116.537902 106.320003 \nL 116.560732 106.352018 \nL 116.67488 106.380801 \nL 116.857516 106.30912 \nL 116.971664 106.337845 \nL 117.108641 106.333161 \nL 117.19996 106.394974 \nL 117.222789 106.361723 \nL 117.359766 106.357002 \nL 117.496744 106.416923 \nL 117.633721 106.412107 \nL 117.839187 106.629837 \nL 117.862017 106.596838 \nL 117.953335 106.529236 \nL 117.998994 106.591659 \nL 118.021824 106.622834 \nL 118.067483 106.557062 \nL 118.113142 106.49138 \nL 118.18163 106.584783 \nL 118.272949 106.709004 \nL 118.318608 106.643426 \nL 118.341437 106.610674 \nL 118.409926 106.70361 \nL 118.546903 106.761785 \nL 118.820858 106.561031 \nL 119.026324 106.71117 \nL 119.277449 106.544361 \nL 119.391597 106.697002 \nL 119.437256 106.632576 \nL 119.551404 106.534467 \nL 119.597063 106.595334 \nL 119.73404 106.652674 \nL 119.825359 106.649236 \nL 119.848188 106.679511 \nL 120.007995 106.766622 \nL 120.213461 106.665701 \nL 120.28195 106.694053 \nL 120.304779 106.662273 \nL 120.464586 106.563776 \nL 120.487416 106.593783 \nL 120.510245 106.623775 \nL 120.555904 106.5605 \nL 120.807029 106.398155 \nL 120.921177 106.424998 \nL 121.058155 106.359294 \nL 121.080984 106.389102 \nL 121.172302 106.44712 \nL 121.195132 106.41585 \nL 121.400598 106.317826 \nL 121.423427 106.347497 \nL 121.469087 106.28529 \nL 121.81153 106.002735 \nL 121.857189 106.061904 \nL 121.925678 105.96952 \nL 122.062655 105.96594 \nL 122.176803 106.053119 \nL 122.222462 105.99181 \nL 122.290951 105.9 \nL 122.359439 105.988194 \nL 122.542076 106.043178 \nL 122.610564 106.011467 \nL 122.656223 106.069931 \nL 122.975837 106.29879 \nL 123.135644 106.264272 \nL 123.249792 106.290421 \nL 123.272621 106.260161 \nL 123.432428 106.225884 \nL 123.569406 106.339627 \nL 123.615065 106.279375 \nL 123.637894 106.249278 \nL 123.706383 106.33539 \nL 123.797701 106.332572 \nL 123.820531 106.302538 \nL 124.025997 106.150108 \nL 124.048826 106.178701 \nL 124.39127 106.430818 \nL 124.642395 106.219933 \nL 124.665224 106.248253 \nL 124.89352 106.357134 \nL 125.030497 106.23765 \nL 125.076156 106.293938 \nL 125.350111 106.457997 \nL 125.578407 106.279144 \nL 125.601236 106.307065 \nL 125.852361 106.442094 \nL 126.057827 106.350436 \nL 126.400271 106.594614 \nL 126.560077 106.561094 \nL 126.742714 106.667656 \nL 126.765543 106.638748 \nL 126.811203 106.580993 \nL 126.879691 106.662978 \nL 127.016669 106.65832 \nL 127.244964 106.538846 \nL 127.313453 106.620379 \nL 127.381941 106.534446 \nL 127.45043 106.504396 \nL 127.496089 106.558634 \nL 127.518919 106.585729 \nL 127.587407 106.500075 \nL 127.610237 106.47156 \nL 127.678726 106.552746 \nL 127.792873 106.521351 \nL 127.907021 106.490055 \nL 127.929851 106.517019 \nL 128.203805 106.673828 \nL 128.340783 106.614197 \nL 128.363612 106.640961 \nL 128.409271 106.694436 \nL 128.47776 106.609723 \nL 128.728885 106.464694 \nL 128.843033 106.433882 \nL 129.071329 106.318052 \nL 129.390942 106.526061 \nL 129.52792 106.467649 \nL 129.550749 106.494035 \nL 129.710556 106.516172 \nL 130.00734 106.31872 \nL 130.258465 106.445785 \nL 130.441102 106.333377 \nL 130.463931 106.359478 \nL 130.737886 106.511599 \nL 131.080329 106.262526 \nL 131.217307 106.258846 \nL 131.377114 106.22815 \nL 131.651068 106.378924 \nL 131.765216 106.349421 \nL 131.788046 106.375066 \nL 131.856534 106.451914 \nL 131.925023 106.371217 \nL 132.039171 106.394223 \nL 132.062 106.419762 \nL 132.130489 106.339312 \nL 132.313125 106.282088 \nL 132.518591 106.35471 \nL 132.701228 106.297739 \nL 132.906694 106.369956 \nL 133.11216 106.286783 \nL 133.271967 106.411466 \nL 133.317626 106.358653 \nL 133.454603 106.303464 \nL 133.477433 106.328572 \nL 133.660069 106.374976 \nL 133.682899 106.348701 \nL 133.751387 106.42372 \nL 133.842706 106.472349 \nL 133.888365 106.419883 \nL 134.093831 106.235562 \nL 134.13949 106.285395 \nL 134.322126 106.382389 \nL 134.344956 106.356335 \nL 134.550422 106.274702 \nL 134.687399 106.271164 \nL 134.824377 106.217078 \nL 134.847206 106.241776 \nL 135.052672 106.312196 \nL 135.121161 106.285221 \nL 135.16682 106.334386 \nL 135.280968 106.306234 \nL 135.577752 106.123239 \nL 135.760388 106.168897 \nL 135.806047 106.11785 \nL 135.874536 106.191087 \nL 135.920195 106.239847 \nL 135.988684 106.163387 \nL 136.19415 106.083905 \nL 136.285468 106.131456 \nL 136.331127 106.080761 \nL 136.468105 106.077623 \nL 136.71923 106.195366 \nL 136.947525 106.091354 \nL 136.970355 106.115453 \nL 137.038843 106.040076 \nL 137.130162 106.038052 \nL 137.152991 106.062103 \nL 137.358457 106.130998 \nL 137.495435 106.127823 \nL 137.609582 106.198452 \nL 137.655241 106.148536 \nL 137.906367 106.020993 \nL 138.020514 106.091423 \nL 138.066173 106.041811 \nL 138.294469 105.939912 \nL 138.362958 105.962702 \nL 138.408617 105.913364 \nL 138.614083 105.836799 \nL 138.728231 105.858689 \nL 138.75106 105.834149 \nL 139.093503 105.61162 \nL 139.25331 105.728717 \nL 139.298969 105.680026 \nL 139.367458 105.607094 \nL 139.435947 105.677655 \nL 139.687072 105.79245 \nL 139.892538 105.669795 \nL 139.915368 105.693169 \nL 140.006686 105.691581 \nL 140.029515 105.667456 \nL 140.189322 105.641055 \nL 140.212152 105.664349 \nL 140.28064 105.592211 \nL 140.371959 105.496205 \nL 140.440447 105.566025 \nL 140.554595 105.540644 \nL 140.760061 105.466891 \nL 140.897038 105.511877 \nL 140.919868 105.488051 \nL 140.965527 105.440437 \nL 141.034016 105.509816 \nL 141.35363 105.691949 \nL 141.376459 105.668197 \nL 141.444948 105.737066 \nL 141.878709 106.031376 \nL 142.038516 106.004864 \nL 142.426619 106.250771 \nL 142.791892 106.012497 \nL 142.88321 106.102457 \nL 142.951698 106.032169 \nL 143.157164 105.959285 \nL 143.40829 106.068433 \nL 143.613756 105.995837 \nL 143.773562 106.015362 \nL 144.024688 105.896977 \nL 144.38996 106.115805 \nL 144.549767 106.089887 \nL 144.778063 106.175006 \nL 144.983529 106.103272 \nL 145.097677 106.07849 \nL 145.188995 106.121346 \nL 145.303143 106.096596 \nL 145.485779 106.048209 \nL 145.805393 106.219497 \nL 146.056518 106.103193 \nL 146.307643 106.208478 \nL 146.513109 106.137869 \nL 146.741405 106.221048 \nL 146.924041 106.173171 \nL 147.038189 106.148825 \nL 147.175166 106.145955 \nL 147.266484 106.100318 \nL 147.403462 106.097526 \nL 147.51761 106.073401 \nL 147.654587 106.070652 \nL 147.951371 106.216653 \nL 148.111178 106.191555 \nL 148.293814 106.230936 \nL 148.54494 106.117703 \nL 148.636258 106.07276 \nL 148.818894 106.026145 \nL 148.910212 105.981422 \nL 149.115678 105.913269 \nL 149.412463 106.057498 \nL 149.595099 106.011293 \nL 149.869054 106.133695 \nL 150.097349 106.044245 \nL 150.279986 106.083085 \nL 150.439793 106.058823 \nL 150.850725 106.303464 \nL 151.124679 106.171604 \nL 151.284486 106.18931 \nL 151.467123 106.143757 \nL 151.58127 106.120594 \nL 151.763907 106.075304 \nL 152.037862 106.194783 \nL 152.12918 106.234458 \nL 152.357475 106.3126 \nL 152.517282 106.288481 \nL 152.677089 106.30574 \nL 152.859726 106.260618 \nL 152.996703 106.257758 \nL 153.088021 106.296987 \nL 153.293487 106.3542 \nL 153.453294 106.330243 \nL 153.567442 106.307333 \nL 153.864226 106.158235 \nL 154.275158 106.394018 \nL 154.434965 106.370229 \nL 154.549113 106.347497 \nL 154.731749 106.303148 \nL 154.891556 106.320003 \nL 155.028533 106.317122 \nL 155.119852 106.274912 \nL 155.599272 105.964352 \nL 155.73625 105.961976 \nL 155.896056 105.939218 \nL 156.078693 105.976018 \nL 156.170011 106.014306 \nL 156.398307 106.089824 \nL 156.489625 106.127886 \nL 156.695091 106.183527 \nL 156.900557 106.120179 \nL 157.037534 106.117624 \nL 157.174512 106.115074 \nL 157.357148 106.151101 \nL 157.494125 106.148515 \nL 157.608273 106.126708 \nL 157.74525 106.124164 \nL 157.859398 106.102436 \nL 157.973546 106.119932 \nL 158.110523 106.117403 \nL 158.315989 106.055059 \nL 158.452967 106.052625 \nL 158.612774 106.030329 \nL 158.77258 106.046973 \nL 158.932387 106.024752 \nL 159.069365 106.022375 \nL 159.183512 106.039755 \nL 159.388979 106.09413 \nL 159.617274 106.012918 \nL 159.754251 106.010568 \nL 159.982547 105.929824 \nL 160.119524 105.927589 \nL 160.302161 105.886321 \nL 160.461968 105.902912 \nL 160.621775 105.881269 \nL 160.804411 105.916518 \nL 160.964218 105.894927 \nL 161.146854 105.930039 \nL 161.238173 105.966534 \nL 161.397979 105.982863 \nL 161.534957 105.980592 \nL 161.694764 105.996852 \nL 161.831741 105.99457 \nL 161.945889 105.973815 \nL 162.105696 105.952366 \nL 162.197014 105.913258 \nL 162.333991 105.911092 \nL 162.493798 105.927337 \nL 162.722094 105.848827 \nL 162.90473 105.883445 \nL 163.201514 105.7484 \nL 163.338492 105.746465 \nL 163.543958 105.687833 \nL 163.726594 105.722461 \nL 164.000549 105.607667 \nL 164.114697 105.587726 \nL 164.251674 105.586013 \nL 164.388651 105.584299 \nL 164.525629 105.58259 \nL 164.845242 105.725495 \nL 164.98222 105.723618 \nL 165.096367 105.703741 \nL 165.324663 105.627544 \nL 165.507299 105.661715 \nL 165.598618 105.696991 \nL 165.735595 105.695161 \nL 165.895402 105.674848 \nL 166.146527 105.762274 \nL 166.374823 105.686681 \nL 166.580289 105.738196 \nL 166.762925 105.699624 \nL 166.968391 105.750939 \nL 167.105368 105.749062 \nL 167.242346 105.747196 \nL 167.356493 105.763588 \nL 167.584789 105.832104 \nL 167.698937 105.848364 \nL 167.813085 105.828834 \nL 167.972891 105.808705 \nL 168.087039 105.789269 \nL 168.201187 105.805498 \nL 168.406653 105.855966 \nL 168.54363 105.85399 \nL 168.703437 105.869424 \nL 168.886074 105.831363 \nL 169.06871 105.864136 \nL 169.297006 105.825559 \nL 169.479642 105.822993 \nL 169.616619 105.821075 \nL 169.913404 105.72919 \nL 170.050381 105.727393 \nL 170.278677 105.689415 \nL 170.438483 105.70485 \nL 170.552631 105.755734 \nL 170.826586 105.856555 \nL 171.169029 105.730216 \nL 171.328836 105.745472 \nL 171.62562 105.655128 \nL 171.739768 105.601905 \nL 171.990893 105.547225 \nL 172.356166 105.680552 \nL 172.858416 105.434781 \nL 173.086712 105.466581 \nL 173.315007 105.430086 \nL 173.611792 105.512061 \nL 173.771599 105.527296 \nL 173.908576 105.491873 \nL 174.159701 105.438419 \nL 174.410826 105.486511 \nL 174.753269 105.365019 \nL 174.958735 105.379865 \nL 175.118542 105.395105 \nL 175.301179 105.393318 \nL 175.438156 105.425465 \nL 175.73494 105.506004 \nL 175.986065 105.453333 \nL 176.123043 105.418641 \nL 176.305679 105.416833 \nL 176.648123 105.529493 \nL 176.922077 105.460388 \nL 177.104714 105.458532 \nL 177.241691 105.490133 \nL 177.401498 105.471996 \nL 177.584134 105.47013 \nL 177.766771 105.468269 \nL 178.109214 105.350141 \nL 178.31468 105.364603 \nL 178.542976 105.329843 \nL 178.748442 105.344295 \nL 178.953908 105.326158 \nL 179.159374 105.340568 \nL 179.296351 105.371774 \nL 179.547476 105.418016 \nL 179.798601 105.367132 \nL 180.072556 105.429103 \nL 180.278022 105.411024 \nL 180.414999 105.377562 \nL 180.643295 105.343364 \nL 180.780272 105.310076 \nL 181.077056 105.227545 \nL 181.282522 105.24187 \nL 181.465159 105.240388 \nL 181.784773 105.333234 \nL 181.990239 105.315554 \nL 182.104386 105.266978 \nL 182.241364 105.297543 \nL 182.469659 105.327246 \nL 182.720784 105.277703 \nL 182.880591 105.260617 \nL 183.154546 105.195455 \nL 183.291523 105.162982 \nL 183.656796 105.034923 \nL 183.885092 105.064768 \nL 184.364512 104.85902 \nL 184.615638 104.904447 \nL 184.889592 104.840909 \nL 185.049399 104.824638 \nL 185.232036 104.823792 \nL 185.50599 104.884317 \nL 185.688627 104.883392 \nL 185.848434 104.867168 \nL 186.076729 104.835279 \nL 186.259366 104.834422 \nL 186.55615 104.756401 \nL 186.715957 104.740445 \nL 186.875764 104.755102 \nL 187.012741 104.724001 \nL 187.172548 104.738642 \nL 187.400843 104.768203 \nL 187.651968 104.721567 \nL 187.971582 104.811338 \nL 188.222707 104.764817 \nL 188.565151 104.869082 \nL 188.816276 104.822667 \nL 189.250037 104.985911 \nL 189.387015 105.015136 \nL 189.706628 105.103045 \nL 189.843606 105.132054 \nL 190.208879 105.248878 \nL 190.368686 105.262552 \nL 190.574152 105.275842 \nL 190.825277 105.229358 \nL 190.985084 105.213345 \nL 191.281868 105.137211 \nL 191.487334 105.150596 \nL 191.647141 105.164265 \nL 192.012414 105.279459 \nL 192.21788 105.263177 \nL 192.354857 105.232781 \nL 192.537493 105.231435 \nL 192.948425 105.374566 \nL 193.085403 105.402618 \nL 193.24521 105.386667 \nL 193.473505 105.355624 \nL 193.701801 105.382819 \nL 194.067074 105.263787 \nL 194.22688 105.248105 \nL 194.455176 105.217509 \nL 194.592153 105.187643 \nL 194.797619 105.171798 \nL 195.025915 105.199041 \nL 195.208551 105.197763 \nL 195.391188 105.196491 \nL 195.550995 105.209723 \nL 195.80212 105.250907 \nL 195.939097 105.278513 \nL 196.076074 105.248904 \nL 196.28154 105.233138 \nL 196.487006 105.245913 \nL 196.669643 105.244588 \nL 196.82945 105.229216 \nL 197.240382 105.084567 \nL 197.559996 105.167477 \nL 197.765462 105.151989 \nL 198.016587 105.192637 \nL 198.290541 105.134499 \nL 198.496007 105.147237 \nL 198.701473 105.131881 \nL 198.929769 105.158445 \nL 199.089576 105.171399 \nL 199.317871 105.197826 \nL 199.500508 105.196591 \nL 199.705974 105.209134 \nL 199.91144 105.193815 \nL 200.071247 105.178848 \nL 200.276713 105.163613 \nL 200.550667 105.217235 \nL 200.824622 105.160064 \nL 201.052918 105.186197 \nL 201.326872 105.129278 \nL 201.46385 105.1009 \nL 201.669316 105.085918 \nL 201.851952 105.08484 \nL 202.103077 105.042252 \nL 202.262884 105.027669 \nL 202.46835 105.01287 \nL 202.742305 105.065977 \nL 203.084748 104.968726 \nL 203.221725 104.940831 \nL 203.404362 104.939943 \nL 203.678317 104.992851 \nL 204.066419 104.869124 \nL 204.226226 104.854919 \nL 204.386033 104.867736 \nL 204.52301 104.840178 \nL 204.774135 104.798757 \nL 205.002431 104.824754 \nL 205.116579 104.864582 \nL 205.390533 104.917022 \nL 205.778636 104.794899 \nL 205.984102 104.807468 \nL 206.212397 104.779916 \nL 206.395034 104.779238 \nL 206.6005 104.765185 \nL 206.851625 104.804104 \nL 207.07992 104.77672 \nL 207.331045 104.815501 \nL 207.605 104.761589 \nL 207.878955 104.813362 \nL 208.10725 104.786146 \nL 208.358375 104.824649 \nL 208.63233 104.771084 \nL 208.906285 104.822493 \nL 209.203069 104.75597 \nL 209.408535 104.768313 \nL 209.636831 104.741428 \nL 209.933615 104.805487 \nL 210.116251 104.804793 \nL 210.321717 104.817 \nL 210.550013 104.790204 \nL 210.732649 104.789531 \nL 210.915286 104.788863 \nL 211.257729 104.877919 \nL 211.577343 104.79933 \nL 211.828468 104.836961 \nL 212.011104 104.836246 \nL 212.330718 104.911865 \nL 212.559014 104.885274 \nL 212.76448 104.897181 \nL 212.924287 104.909262 \nL 213.198241 104.959037 \nL 213.449366 104.945142 \nL 213.700491 104.982095 \nL 213.928787 104.981001 \nL 214.111423 104.954789 \nL 214.431037 104.902743 \nL 214.682162 104.914288 \nL 215.070265 104.824454 \nL 215.344219 104.848563 \nL 215.526856 104.872962 \nL 215.800811 104.896919 \nL 216.074765 104.870738 \nL 216.32589 104.88222 \nL 216.554186 104.881284 \nL 216.805311 104.892713 \nL 217.102095 104.854173 \nL 217.284732 104.828618 \nL 217.604345 104.777834 \nL 217.923959 104.826226 \nL 218.197914 104.800508 \nL 218.426209 104.799693 \nL 218.722994 104.76171 \nL 218.90563 104.736508 \nL 219.225244 104.686407 \nL 219.590517 104.758851 \nL 219.773153 104.782718 \nL 220.092767 104.830463 \nL 220.298233 104.841897 \nL 220.45804 104.804751 \nL 220.640676 104.828444 \nL 221.005949 104.899957 \nL 221.279904 104.874592 \nL 221.48537 104.861675 \nL 221.690836 104.872978 \nL 222.056109 104.943938 \nL 222.352893 104.906523 \nL 222.53553 104.88171 \nL 222.855143 104.832419 \nL 223.174757 104.879191 \nL 223.448712 104.854189 \nL 223.608519 104.817725 \nL 223.905303 104.780873 \nL 224.06511 104.744572 \nL 224.361894 104.707951 \nL 224.635849 104.730925 \nL 224.818485 104.754114 \nL 225.138099 104.800498 \nL 225.412054 104.775905 \nL 225.800156 104.857248 \nL 226.005622 104.868267 \nL 226.302406 104.902444 \nL 226.850316 104.736066 \nL 227.078611 104.735377 \nL 227.329736 104.722929 \nL 227.535202 104.710648 \nL 227.763498 104.710001 \nL 228.060282 104.744099 \nL 228.448384 104.661583 \nL 228.67668 104.661 \nL 228.927805 104.648777 \nL 229.156101 104.648209 \nL 229.361567 104.659265 \nL 229.498544 104.612718 \nL 229.68118 104.635387 \nL 229.955135 104.657772 \nL 230.22909 104.634083 \nL 230.548704 104.679258 \nL 230.75417 104.690187 \nL 231.165102 104.780615 \nL 231.370568 104.791392 \nL 231.713011 104.847312 \nL 232.078284 104.777724 \nL 232.489216 104.867279 \nL 232.877318 104.786545 \nL 233.105614 104.78582 \nL 233.28825 104.807847 \nL 233.448057 104.773439 \nL 233.676353 104.772729 \nL 233.83616 104.738427 \nL 234.110114 104.715127 \nL 234.33841 104.714496 \nL 234.521046 104.736445 \nL 234.84066 104.780357 \nL 235.160274 104.73461 \nL 235.411399 104.745066 \nL 235.639694 104.744404 \nL 235.913649 104.76589 \nL 236.278922 104.698078 \nL 236.530047 104.708519 \nL 237.100786 104.540969 \nL 237.306252 104.52955 \nL 237.762843 104.418499 \nL 238.013968 104.429239 \nL 238.242264 104.428976 \nL 238.379241 104.384858 \nL 238.744514 104.318718 \nL 239.018469 104.340478 \nL 239.269594 104.329375 \nL 239.45223 104.307416 \nL 239.703355 104.296381 \nL 239.954481 104.307174 \nL 240.388242 104.209128 \nL 240.548049 104.176555 \nL 240.913322 104.111598 \nL 241.164447 104.122564 \nL 241.347083 104.144287 \nL 241.598209 104.15519 \nL 241.803675 104.166051 \nL 242.146118 104.22 \nL 242.420073 104.198488 \nL 242.831005 104.284379 \nL 243.013641 104.305754 \nL 243.196277 104.284253 \nL 243.493062 104.252079 \nL 243.812675 104.29472 \nL 244.040971 104.29463 \nL 244.383414 104.347701 \nL 244.634539 104.336908 \nL 244.908494 104.357963 \nL 245.159619 104.34718 \nL 245.342256 104.325884 \nL 245.593381 104.31517 \nL 245.867335 104.336151 \nL 246.14129 104.314896 \nL 246.415245 104.335815 \nL 246.826177 104.251516 \nL 247.031643 104.240992 \nL 247.396916 104.178101 \nL 247.739359 104.230456 \nL 248.036143 104.199119 \nL 248.241609 104.18871 \nL 248.424246 104.20958 \nL 248.675371 104.22 \nL 248.926496 104.209612 \nL 249.086303 104.178469 \nL 249.291769 104.188878 \nL 249.497235 104.178553 \nL 249.74836 104.168259 \nL 249.930996 104.14763 \nL 250.136462 104.158029 \nL 250.456076 104.199382 \nL 250.661542 104.209696 \nL 250.889838 104.209717 \nL 251.186622 104.17891 \nL 251.574724 104.250754 \nL 252.031315 104.148398 \nL 252.350929 104.189361 \nL 252.602054 104.179205 \nL 252.921668 104.22 \nL 253.058645 104.260701 \nL 253.195623 104.22 \nL 253.515237 104.179394 \nL 253.766362 104.189582 \nL 254.131635 104.128915 \nL 254.428419 104.139156 \nL 254.816521 104.088887 \nL 255.090476 104.089066 \nL 255.501408 104.02903 \nL 255.821022 104.049396 \nL 256.140635 104.029629 \nL 256.551567 104.090012 \nL 256.985329 104.02045 \nL 257.282113 104.030712 \nL 257.624557 104.001188 \nL 257.967 104.031343 \nL 258.355102 103.982157 \nL 258.811693 104.061792 \nL 259.176966 104.022595 \nL 259.49658 104.042614 \nL 259.770535 104.042856 \nL 260.272785 104.141458 \nL 260.820694 104.024172 \nL 261.07182 104.014635 \nL 261.459922 103.966217 \nL 261.848024 104.015403 \nL 262.121979 104.015676 \nL 262.555741 104.084072 \nL 262.966673 104.026201 \nL 263.172139 103.99735 \nL 263.491752 103.978361 \nL 263.697218 103.949626 \nL 263.925514 103.969214 \nL 264.267957 103.998517 \nL 264.541912 103.998801 \nL 264.861526 104.018347 \nL 265.112651 104.028178 \nL 265.363776 104.018831 \nL 265.637731 104.019094 \nL 265.934515 104.028924 \nL 266.276958 104.00062 \nL 266.619402 104.029545 \nL 266.870527 104.039281 \nL 267.21297 104.068058 \nL 267.532584 104.049322 \nL 267.806538 104.049543 \nL 268.126152 104.030891 \nL 268.354448 104.012207 \nL 268.628402 104.01247 \nL 268.902357 104.012732 \nL 269.153482 104.022395 \nL 269.358948 103.994375 \nL 269.701392 103.966575 \nL 270.043835 103.9951 \nL 270.409108 103.958058 \nL 270.660233 103.949016 \nL 271.116824 103.874996 \nL 271.482097 103.912815 \nL 271.710392 103.931731 \nL 272.007177 103.941414 \nL 272.189813 103.978761 \nL 272.555086 104.016223 \nL 272.8747 103.998023 \nL 273.057336 103.961244 \nL 273.331291 103.96157 \nL 273.628075 103.971138 \nL 273.8792 103.980622 \nL 274.198814 103.999358 \nL 274.495598 103.990484 \nL 274.815212 104.009147 \nL 275.157655 103.98202 \nL 275.43161 103.982315 \nL 275.637076 104.009936 \nL 276.025178 104.055893 \nL 276.299133 104.056093 \nL 276.664406 104.092725 \nL 276.98402 104.074756 \nL 277.417781 104.138462 \nL 277.691736 104.138557 \nL 278.034179 104.165788 \nL 278.285304 104.174873 \nL 278.673407 104.22 \nL 279.107169 104.157062 \nL 279.312635 104.130166 \nL 279.700737 104.085481 \nL 280.04318 104.112544 \nL 280.362794 104.094817 \nL 280.728067 104.130734 \nL 281.390124 103.979676 \nL 281.778227 104.024508 \nL 282.052181 104.02475 \nL 282.326136 104.024982 \nL 282.714238 103.981074 \nL 283.056682 104.007938 \nL 283.330636 104.00819 \nL 283.467614 104.008316 \nL 283.467614 104.008316 \n\" clip-path=\"url(#p12b8914372)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 55.194886 16.02 \nL 55.217716 16.02 \nL 55.354693 104.22 \nL 55.400352 86.579996 \nL 55.491671 91.619995 \nL 55.651477 74.819996 \nL 55.834114 95.095862 \nL 55.856943 92.460001 \nL 55.902603 98.7075 \nL 55.971091 106.74 \nL 56.03958 104.22 \nL 56.062409 101.958456 \nL 56.108069 106.371217 \nL 56.130898 104.22 \nL 56.336364 112.867058 \nL 56.496171 104.22 \nL 56.519001 105.714917 \nL 56.587489 109.910322 \nL 56.633148 106.97625 \nL 56.655978 105.576923 \nL 56.701637 108.169256 \nL 56.770126 111.78 \nL 56.815785 109.120002 \nL 56.975592 105.336457 \nL 57.203887 113.139099 \nL 57.226717 112.06 \nL 57.432183 115.801819 \nL 57.59199 112.540754 \nL 57.683308 113.84182 \nL 57.637649 112.386667 \nL 57.728967 113.670001 \nL 57.820285 110.302757 \nL 57.888774 110.890588 \nL 57.957263 112.89541 \nL 58.048581 112.619999 \nL 58.276876 108.111175 \nL 58.299706 108.726569 \nL 58.368195 108.000002 \nL 58.391024 107.347661 \nL 58.436683 108.537481 \nL 58.528001 108.42 \nL 58.573661 109.547517 \nL 58.642149 110.02263 \nL 58.687808 108.80182 \nL 58.733467 109.873848 \nL 58.779127 108.685821 \nL 58.801956 108.103021 \nL 58.847615 109.150436 \nL 58.916104 110.673658 \nL 58.961763 109.533255 \nL 58.984593 108.973292 \nL 59.030252 109.960828 \nL 59.12157 110.847747 \nL 59.075911 109.893684 \nL 59.167229 110.771998 \nL 59.486843 105.62 \nL 59.64665 107.819998 \nL 59.532502 105.605338 \nL 59.669479 107.354012 \nL 59.692309 106.892725 \nL 59.737968 107.748002 \nL 59.760798 107.291641 \nL 59.852116 107.23171 \nL 59.920604 108.460385 \nL 60.034752 107.946758 \nL 60.057582 108.341495 \nL 60.103241 107.486665 \nL 60.12607 107.878063 \nL 60.263048 106.98861 \nL 60.285877 107.369998 \nL 60.331536 106.561594 \nL 60.377196 107.314736 \nL 60.400025 106.916072 \nL 60.445684 107.656365 \nL 60.468514 107.261381 \nL 60.537002 106.847235 \nL 60.628321 108.279414 \nL 60.810957 106.719597 \nL 60.833787 107.065164 \nL 60.879446 106.336799 \nL 61.039253 105.249572 \nL 61.130571 106.585519 \nL 61.17623 105.896804 \nL 61.313207 105.203641 \nL 61.358866 105.847308 \nL 61.404526 105.189231 \nL 61.450185 105.823635 \nL 61.495844 105.175236 \nL 61.541503 105.800645 \nL 61.564332 106.110001 \nL 61.609992 105.471065 \nL 61.724139 104.527316 \nL 61.746969 104.832498 \nL 61.792628 105.436552 \nL 61.861117 105.12307 \nL 61.998094 103.925012 \nL 62.020924 104.22 \nL 62.135071 105.087542 \nL 62.157901 104.796471 \nL 62.22639 104.505436 \nL 62.249219 104.789032 \nL 62.523174 106.959133 \nL 62.546003 106.677587 \nL 62.591662 107.20523 \nL 62.614492 106.925524 \nL 62.637322 107.186972 \nL 62.70581 106.892725 \nL 62.865617 106.052047 \nL 62.979765 106.798948 \nL 62.911276 106.041238 \nL 63.002594 106.534283 \nL 63.071083 105.749478 \nL 63.116742 106.247586 \nL 63.139572 106.494497 \nL 63.185231 105.978973 \nL 63.20806 106.224544 \nL 63.23089 105.96901 \nL 63.276549 106.456057 \nL 63.299379 106.202022 \nL 63.322208 106.443529 \nL 63.390697 106.18 \nL 63.550504 104.460324 \nL 63.618992 104.696759 \nL 63.641822 104.933208 \nL 63.687481 104.45646 \nL 63.710311 104.691659 \nL 63.870118 103.988508 \nL 63.938606 104.22 \nL 63.961436 103.990905 \nL 64.052754 103.086321 \nL 64.098413 103.543271 \nL 64.25822 104.22 \nL 64.372368 104.001146 \nL 64.395197 104.22 \nL 64.440856 103.785519 \nL 64.577834 102.507374 \nL 64.623493 102.941739 \nL 64.806129 103.801995 \nL 64.828959 103.594465 \nL 64.874618 104.01247 \nL 64.897448 103.805917 \nL 65.125743 105.029172 \nL 65.171402 104.622738 \nL 65.239891 104.820001 \nL 65.30838 104.617297 \nL 65.354039 105.01103 \nL 65.376868 104.811948 \nL 65.422527 105.202184 \nL 65.445357 105.004001 \nL 65.468186 105.197826 \nL 65.513846 104.804104 \nL 65.719312 103.838185 \nL 65.993266 105.336457 \nL 66.084584 104.958075 \nL 66.107414 105.140671 \nL 66.175903 105.317925 \nL 66.198732 105.133043 \nL 66.31288 104.581475 \nL 66.33571 104.761106 \nL 66.358539 104.940001 \nL 66.404198 104.578536 \nL 66.564005 104.043245 \nL 66.609664 104.396046 \nL 66.678153 104.22 \nL 66.700982 104.045348 \nL 66.746642 104.393964 \nL 66.769471 104.22 \nL 66.883619 104.391929 \nL 67.134744 102.873439 \nL 67.157574 103.044001 \nL 67.34021 104.054527 \nL 67.36304 103.889663 \nL 67.431528 103.72726 \nL 67.454358 103.892123 \nL 67.522846 103.730908 \nL 67.591335 104.22 \nL 67.728312 103.899273 \nL 67.751142 104.059931 \nL 67.796801 103.741517 \nL 67.819631 103.901586 \nL 67.888119 103.428255 \nL 67.956608 103.589996 \nL 68.093585 104.22 \nL 68.116415 104.064442 \nL 68.34471 103.149985 \nL 68.413199 103.307583 \nL 68.436029 103.157345 \nL 68.458858 103.007632 \nL 68.504517 103.313839 \nL 68.550176 103.617954 \nL 68.595836 103.32 \nL 68.801302 102.594874 \nL 68.938279 102.903583 \nL 68.983938 102.616365 \nL 69.029597 102.912257 \nL 69.280722 103.934559 \nL 69.303552 103.792532 \nL 69.349211 104.077973 \nL 69.486188 104.36067 \nL 69.600336 103.940888 \nL 69.623166 104.080665 \nL 69.805802 104.632795 \nL 69.965609 104.22 \nL 69.988438 104.355902 \nL 70.034098 104.084513 \nL 70.171075 103.54877 \nL 70.193904 103.683825 \nL 70.262393 103.819701 \nL 70.285223 103.687074 \nL 70.308052 103.554836 \nL 70.353711 103.822109 \nL 70.513518 104.482499 \nL 70.536348 104.351055 \nL 70.627666 104.089718 \nL 70.650496 104.22 \nL 70.810302 104.606278 \nL 70.855962 104.348384 \nL 70.92445 104.475654 \nL 71.084257 104.852711 \nL 71.152746 104.472001 \nL 71.221234 104.596389 \nL 71.403871 105.088357 \nL 71.563678 104.711363 \nL 71.586507 104.833349 \nL 71.632166 104.58699 \nL 71.837632 103.736712 \nL 71.860462 103.858026 \nL 71.997439 104.339673 \nL 72.020269 104.22 \nL 72.225735 103.393495 \nL 72.248564 103.512517 \nL 72.317053 103.632779 \nL 72.339883 103.516281 \nL 72.362712 103.400077 \nL 72.408371 103.635891 \nL 72.47686 103.754565 \nL 72.49969 103.638972 \nL 72.522519 103.523683 \nL 72.568178 103.757005 \nL 72.591008 103.642021 \nL 72.659496 103.52914 \nL 72.705156 103.760621 \nL 72.819303 103.421295 \nL 72.842133 103.536279 \nL 72.887792 103.765363 \nL 72.933451 103.539791 \nL 73.047599 103.206205 \nL 73.070428 103.32 \nL 73.207406 103.550126 \nL 73.48136 102.680344 \nL 73.686826 103.458715 \nL 73.709656 103.351039 \nL 73.892292 102.92927 \nL 73.960781 103.041141 \nL 73.983611 102.935536 \nL 74.00644 102.830183 \nL 74.052099 103.04684 \nL 74.074929 103.154779 \nL 74.120588 102.94482 \nL 74.143418 103.052486 \nL 74.348884 102.54 \nL 74.440202 102.756962 \nL 74.463031 102.654322 \nL 74.53152 102.76387 \nL 74.600009 102.458073 \nL 74.622838 102.563657 \nL 74.668497 102.360984 \nL 74.691327 102.466316 \nL 74.828304 102.068783 \nL 74.851134 102.173599 \nL 75.03377 102.800691 \nL 75.0566 102.701058 \nL 75.239236 102.313512 \nL 75.262066 102.415911 \nL 75.307725 102.219999 \nL 75.353384 102.02498 \nL 75.399043 102.22903 \nL 75.421873 102.330714 \nL 75.467532 102.136536 \nL 75.55885 101.7508 \nL 75.604509 101.95341 \nL 75.741486 102.36007 \nL 75.764316 102.264348 \nL 75.832805 102.173368 \nL 75.855634 102.27298 \nL 75.878464 102.372371 \nL 75.924123 102.182379 \nL 75.946952 102.281539 \nL 75.969782 102.186847 \nL 76.015441 102.384515 \nL 76.220907 102.880736 \nL 76.449203 102.327297 \nL 76.472032 102.42386 \nL 76.517691 102.23904 \nL 76.745987 101.699995 \nL 76.814476 101.614935 \nL 76.860135 101.806105 \nL 76.997112 101.452216 \nL 77.019942 101.547275 \nL 77.065601 101.736784 \nL 77.11126 101.558399 \nL 77.179748 101.658169 \nL 77.248237 101.392495 \nL 77.430874 101.777538 \nL 77.59068 101.5255 \nL 77.704828 101.628508 \nL 77.773317 101.72545 \nL 77.818976 101.552659 \nL 77.887465 101.649348 \nL 77.910294 101.563373 \nL 77.955953 101.391948 \nL 78.001612 101.574003 \nL 78.184249 101.944998 \nL 78.366885 101.615671 \nL 78.549522 101.980547 \nL 78.732158 101.656045 \nL 78.800647 101.919133 \nL 78.869136 101.840812 \nL 78.937624 101.762944 \nL 78.960454 101.849939 \nL 78.983283 101.936776 \nL 79.028942 101.772344 \nL 79.051772 101.859002 \nL 79.257238 101.461142 \nL 79.280068 101.547275 \nL 79.325727 101.385598 \nL 79.348556 101.471562 \nL 79.462704 101.23579 \nL 79.485534 101.321408 \nL 79.599681 101.417382 \nL 79.736659 100.941191 \nL 79.782318 101.110912 \nL 79.805147 101.195531 \nL 79.850807 101.037944 \nL 80.079102 100.582056 \nL 80.216079 100.923559 \nL 80.238909 100.846227 \nL 80.375886 100.545004 \nL 80.398716 100.62814 \nL 80.467205 100.558262 \nL 80.512864 100.723788 \nL 80.581352 100.653963 \nL 80.604182 100.736342 \nL 80.786818 101.075616 \nL 80.832477 100.924274 \nL 80.878137 101.086782 \nL 80.969455 101.410085 \nL 81.037943 101.339682 \nL 81.152091 101.119829 \nL 81.174921 101.199979 \nL 81.19775 101.280003 \nL 81.243409 101.130679 \nL 81.266239 101.056217 \nL 81.311898 101.215803 \nL 81.448875 101.691247 \nL 81.494535 101.542638 \nL 81.517364 101.468523 \nL 81.563023 101.62588 \nL 81.768489 102.024465 \nL 81.836978 101.954587 \nL 81.859807 102.031972 \nL 81.882637 102.109231 \nL 81.928296 101.962326 \nL 81.951126 102.039437 \nL 82.088103 101.900912 \nL 82.156592 101.98142 \nL 82.179421 101.908756 \nL 82.24791 101.988969 \nL 82.293569 101.84424 \nL 82.362058 101.924285 \nL 82.384887 101.85221 \nL 82.453376 101.784351 \nL 82.476205 101.860138 \nL 82.636012 102.093817 \nL 82.841478 101.600194 \nL 82.864308 101.675066 \nL 82.909967 101.824442 \nL 82.955626 101.683435 \nL 83.138263 101.411999 \nL 83.298069 101.785907 \nL 83.320899 101.716355 \nL 83.480706 101.517099 \nL 83.594854 101.740485 \nL 83.617683 101.671691 \nL 83.77749 101.474748 \nL 83.845979 101.411084 \nL 83.914467 101.627941 \nL 83.937297 101.559998 \nL 83.982956 101.70399 \nL 84.005786 101.636152 \nL 84.188422 101.929994 \nL 84.234081 101.795023 \nL 84.27974 101.937176 \nL 84.530865 102.436792 \nL 84.667843 102.172012 \nL 84.690672 102.241805 \nL 84.736331 102.381077 \nL 84.80482 102.317382 \nL 85.010286 101.723137 \nL 85.055945 101.861715 \nL 85.261411 102.212418 \nL 85.581025 101.571353 \nL 85.649514 101.643376 \nL 85.672343 101.579281 \nL 85.786491 101.260268 \nL 85.83215 101.396028 \nL 85.991957 101.737331 \nL 86.014787 101.673888 \nL 86.151764 101.55515 \nL 86.197423 101.688871 \nL 86.243082 101.562984 \nL 86.288741 101.437464 \nL 86.35723 101.508141 \nL 86.380059 101.574644 \nL 86.425719 101.449661 \nL 86.517037 101.329252 \nL 86.539866 101.395544 \nL 86.562696 101.461742 \nL 86.608355 101.337642 \nL 86.631185 101.403745 \nL 86.699673 101.473728 \nL 86.790991 101.226927 \nL 86.905139 101.428054 \nL 86.927969 101.366661 \nL 86.950798 101.305342 \nL 86.996457 101.436066 \nL 87.156264 101.638844 \nL 87.201923 101.516794 \nL 87.247583 101.646193 \nL 87.316071 101.714315 \nL 87.338901 101.653501 \nL 87.430219 101.53592 \nL 87.453049 101.600194 \nL 87.498708 101.728478 \nL 87.544367 101.607585 \nL 87.818321 101.136084 \nL 87.863981 101.26358 \nL 87.932469 101.208296 \nL 88.046617 100.912498 \nL 88.092276 101.039416 \nL 88.137935 101.165986 \nL 88.183594 101.048216 \nL 88.320572 100.939835 \nL 88.503208 101.199453 \nL 88.571697 101.145357 \nL 88.594526 101.207707 \nL 88.685845 101.336075 \nL 88.708674 101.277995 \nL 88.731504 101.219998 \nL 88.777163 101.343908 \nL 89.005458 101.720403 \nL 89.051117 101.604904 \nL 89.119606 101.669493 \nL 89.142436 101.730486 \nL 89.188095 101.615439 \nL 89.302243 101.56515 \nL 89.530538 101.934421 \nL 89.576197 101.820394 \nL 89.621856 101.940477 \nL 89.713175 102.063094 \nL 89.736004 102.006265 \nL 89.918641 101.786096 \nL 89.987129 101.848719 \nL 90.009959 101.792478 \nL 90.055618 101.680207 \nL 90.101277 101.798818 \nL 90.124107 101.858014 \nL 90.169766 101.746026 \nL 90.283913 101.582025 \nL 90.306743 101.641052 \nL 90.420891 101.706524 \nL 90.44372 101.651072 \nL 90.489379 101.768411 \nL 90.512209 101.713022 \nL 90.535039 101.771586 \nL 90.580698 101.661008 \nL 90.603527 101.719488 \nL 90.672016 101.781028 \nL 90.717675 101.67087 \nL 90.923141 101.967131 \nL 91.014459 101.860506 \nL 91.037289 101.918155 \nL 91.174266 102.150626 \nL 91.197096 102.096046 \nL 91.379732 101.88431 \nL 91.653687 102.343404 \nL 91.722175 102.291832 \nL 91.745005 102.348094 \nL 91.927641 102.576527 \nL 92.224426 101.991902 \nL 92.247255 102.047586 \nL 92.338573 102.161276 \nL 92.361403 102.1084 \nL 92.429892 102.166323 \nL 92.49838 102.008252 \nL 92.703846 102.288615 \nL 92.772335 102.345686 \nL 92.863653 102.136536 \nL 93.02346 102.304922 \nL 93.137608 102.25764 \nL 93.320244 102.478166 \nL 93.411563 102.377019 \nL 93.434392 102.430736 \nL 93.502881 102.59153 \nL 93.54854 102.488533 \nL 93.617029 102.543996 \nL 93.685517 102.390119 \nL 93.822495 102.500803 \nL 93.868154 102.398762 \nL 93.913813 102.504851 \nL 93.959472 102.610698 \nL 94.005131 102.508888 \nL 94.027961 102.458073 \nL 94.07362 102.563657 \nL 94.187767 102.826556 \nL 94.256256 102.777475 \nL 94.324745 102.831424 \nL 94.370404 102.730308 \nL 94.393233 102.782511 \nL 94.438893 102.681627 \nL 94.484552 102.580974 \nL 94.530211 102.685202 \nL 94.644359 102.740644 \nL 94.667188 102.690522 \nL 94.712847 102.79413 \nL 94.781336 102.745764 \nL 94.918313 103.05481 \nL 95.009631 102.956386 \nL 95.032461 103.007632 \nL 95.055291 103.058805 \nL 95.10095 102.959277 \nL 95.169438 102.810406 \nL 95.237927 102.863072 \nL 95.260757 102.914076 \nL 95.306416 102.815221 \nL 95.352075 102.716587 \nL 95.420563 102.769179 \nL 95.671689 103.126202 \nL 95.694518 103.077132 \nL 95.740177 103.177679 \nL 95.808666 103.328086 \nL 95.877155 103.28012 \nL 96.10545 102.891839 \nL 96.12828 102.941739 \nL 96.173939 103.041383 \nL 96.219598 102.944578 \nL 96.356575 102.655478 \nL 96.425064 102.706882 \nL 96.6077 102.907936 \nL 96.699019 102.716871 \nL 96.744678 102.81539 \nL 96.904485 103.062012 \nL 96.927314 103.014425 \nL 97.13278 102.780388 \nL 97.15561 102.829132 \nL 97.201269 102.734829 \nL 97.269757 102.785077 \nL 97.315417 102.691069 \nL 97.429564 102.838153 \nL 97.452394 102.79127 \nL 97.63503 102.607743 \nL 97.726349 102.705842 \nL 97.749178 102.659358 \nL 98.091621 102.155746 \nL 98.205769 102.208012 \nL 98.251428 102.116664 \nL 98.297087 102.212271 \nL 98.456894 102.359239 \nL 98.571042 102.317739 \nL 98.593872 102.365106 \nL 98.639531 102.27441 \nL 98.66236 102.321735 \nL 98.799338 102.143076 \nL 98.822167 102.190296 \nL 98.913485 102.286596 \nL 98.936315 102.241595 \nL 98.959145 102.196646 \nL 99.004804 102.290623 \nL 99.027633 102.337548 \nL 99.073292 102.247767 \nL 99.164611 102.16032 \nL 99.18744 102.20714 \nL 99.278758 102.302609 \nL 99.301588 102.257976 \nL 99.347247 102.168836 \nL 99.415736 102.217528 \nL 99.644031 102.499468 \nL 99.666861 102.455097 \nL 99.71252 102.547318 \nL 99.872327 102.68844 \nL 99.895156 102.644196 \nL 99.940816 102.735755 \nL 100.146282 102.966395 \nL 100.351748 102.749255 \nL 100.420236 102.79598 \nL 100.443066 102.75222 \nL 100.71702 102.407373 \nL 100.73985 102.452469 \nL 100.785509 102.365947 \nL 101.013805 102.111639 \nL 101.127952 102.160688 \nL 101.173612 102.075186 \nL 101.2421 102.122079 \nL 101.26493 102.166807 \nL 101.310589 102.081557 \nL 101.333418 102.038996 \nL 101.379078 102.128304 \nL 101.401907 102.085774 \nL 101.424737 102.130365 \nL 101.470396 102.045441 \nL 101.538884 102.005224 \nL 101.561714 102.04972 \nL 101.653032 102.140626 \nL 101.675862 102.098349 \nL 101.858498 101.847878 \nL 101.881328 101.892143 \nL 101.949816 102.024686 \nL 102.018305 101.98491 \nL 102.200942 101.7367 \nL 102.223771 101.780702 \nL 102.315089 101.956269 \nL 102.360748 101.873123 \nL 102.452067 101.792478 \nL 102.474896 101.836218 \nL 102.680362 102.143213 \nL 102.703192 102.101839 \nL 102.77168 102.147198 \nL 102.81734 102.064661 \nL 102.840169 102.107927 \nL 102.885828 102.025548 \nL 102.908658 102.068783 \nL 102.931487 102.027651 \nL 102.977146 102.113983 \nL 103.022806 102.200148 \nL 103.091294 102.161024 \nL 103.159783 102.038081 \nL 103.205442 102.123993 \nL 103.31959 102.170781 \nL 103.388078 102.131931 \nL 103.410908 102.174661 \nL 103.433738 102.217349 \nL 103.479397 102.135874 \nL 103.547885 102.097203 \nL 103.570715 102.139806 \nL 103.593544 102.182379 \nL 103.639204 102.101209 \nL 103.753351 102.064735 \nL 103.867499 102.193839 \nL 103.890329 102.153454 \nL 104.164283 101.836218 \nL 104.187113 101.878411 \nL 104.232772 101.798503 \nL 104.278431 101.718742 \nL 104.34692 101.763175 \nL 104.369749 101.805243 \nL 104.415408 101.725702 \nL 104.438238 101.767728 \nL 104.529556 101.690679 \nL 104.552386 101.732621 \nL 104.666534 101.860411 \nL 104.689363 101.820825 \nL 104.872 101.505534 \nL 104.940488 101.549725 \nL 104.986147 101.633019 \nL 105.031806 101.554614 \nL 105.123125 101.47887 \nL 105.145954 101.520411 \nL 105.328591 101.690826 \nL 105.511227 101.539999 \nL 105.579716 101.663479 \nL 105.625375 101.585968 \nL 105.808011 101.436413 \nL 105.89933 101.441418 \nL 105.922159 101.402999 \nL 105.967818 101.48481 \nL 106.218943 101.774383 \nL 106.355921 101.702245 \nL 106.424409 101.823474 \nL 106.470068 101.747099 \nL 106.675534 101.483296 \nL 106.698364 101.523587 \nL 106.766853 101.644248 \nL 106.812512 101.568546 \nL 107.017978 101.384862 \nL 107.040807 101.424931 \nL 107.086466 101.349817 \nL 107.109296 101.312303 \nL 107.154955 101.392337 \nL 107.223444 101.434741 \nL 107.246273 101.397289 \nL 107.42891 101.253023 \nL 107.588717 101.377312 \nL 107.611546 101.340155 \nL 107.657205 101.41939 \nL 107.839842 101.582025 \nL 107.95399 101.549588 \nL 108.068137 101.593412 \nL 108.227944 101.411568 \nL 108.250774 101.450712 \nL 108.319262 101.49217 \nL 108.342092 101.455465 \nL 108.43341 101.460207 \nL 108.547558 101.50383 \nL 108.593217 101.430767 \nL 108.638876 101.508467 \nL 108.661706 101.547275 \nL 108.707365 101.474327 \nL 108.912831 101.297488 \nL 109.026979 101.34107 \nL 109.141126 101.309853 \nL 109.163956 101.348377 \nL 109.209615 101.27627 \nL 109.346592 101.209379 \nL 109.529229 101.367671 \nL 109.643377 101.336685 \nL 109.803184 101.529401 \nL 109.826013 101.493684 \nL 109.894502 101.460301 \nL 109.917331 101.498237 \nL 110.00865 101.649642 \nL 110.054309 101.578397 \nL 110.259775 101.40549 \nL 110.328263 101.445497 \nL 110.351093 101.410148 \nL 110.419582 101.377186 \nL 110.442411 101.414796 \nL 110.533729 101.49217 \nL 110.556559 101.456937 \nL 110.739195 101.321072 \nL 110.807684 101.433217 \nL 110.853343 101.363171 \nL 110.921832 101.330566 \nL 110.944661 101.367849 \nL 111.058809 101.409707 \nL 111.150127 101.342352 \nL 111.172957 101.379478 \nL 111.355593 101.532072 \nL 111.469741 101.43022 \nL 111.492571 101.467104 \nL 111.5154 101.503957 \nL 111.561059 101.434741 \nL 111.583889 101.40017 \nL 111.629548 101.473781 \nL 111.766525 101.622747 \nL 111.789355 101.588228 \nL 111.949162 101.418307 \nL 111.971991 101.454886 \nL 112.108969 101.532271 \nL 112.154628 101.46375 \nL 112.200287 101.536572 \nL 112.337264 101.613452 \nL 112.519901 101.481309 \nL 112.656878 101.557884 \nL 112.702537 101.490004 \nL 112.748196 101.562111 \nL 112.885174 101.638192 \nL 112.908003 101.604347 \nL 112.953662 101.676106 \nL 113.113469 101.787379 \nL 113.227617 101.757476 \nL 113.341765 101.796926 \nL 113.547231 101.632988 \nL 113.59289 101.703938 \nL 113.638549 101.637025 \nL 113.798356 101.54103 \nL 113.889674 101.682362 \nL 113.935333 101.615807 \nL 114.09514 101.520348 \nL 114.414754 101.874794 \nL 114.460413 101.808681 \nL 114.506072 101.878411 \nL 114.574561 101.982797 \nL 114.62022 101.916778 \nL 114.780027 101.754049 \nL 114.802856 101.788756 \nL 114.917004 101.827112 \nL 115.053981 101.765331 \nL 115.259447 102.008294 \nL 115.282277 101.975637 \nL 115.487743 101.749601 \nL 115.510572 101.783909 \nL 115.693209 101.924338 \nL 115.784527 101.927797 \nL 115.898675 102.031583 \nL 115.944334 101.966952 \nL 116.058482 101.938111 \nL 116.241118 102.076826 \nL 116.263948 102.044663 \nL 116.355266 101.982092 \nL 116.378096 102.015822 \nL 116.537902 102.119997 \nL 116.560732 102.087982 \nL 116.67488 102.059194 \nL 116.857516 102.13088 \nL 116.971664 102.102155 \nL 117.108641 102.106844 \nL 117.19996 102.045031 \nL 117.222789 102.078277 \nL 117.359766 102.082998 \nL 117.496744 102.023077 \nL 117.633721 102.027893 \nL 117.839187 101.810163 \nL 117.862017 101.843157 \nL 117.953335 101.910764 \nL 117.998994 101.848341 \nL 118.021824 101.817166 \nL 118.067483 101.882943 \nL 118.113142 101.948615 \nL 118.18163 101.855217 \nL 118.272949 101.731001 \nL 118.318608 101.796568 \nL 118.341437 101.82932 \nL 118.409926 101.736385 \nL 118.546903 101.678209 \nL 118.820858 101.878969 \nL 119.026324 101.728836 \nL 119.277449 101.895644 \nL 119.391597 101.742998 \nL 119.437256 101.80743 \nL 119.551404 101.905528 \nL 119.597063 101.844661 \nL 119.73404 101.787326 \nL 119.825359 101.790764 \nL 119.848188 101.760483 \nL 120.007995 101.673383 \nL 120.213461 101.774299 \nL 120.28195 101.745942 \nL 120.304779 101.777727 \nL 120.464586 101.876224 \nL 120.487416 101.846217 \nL 120.510245 101.81623 \nL 120.555904 101.879494 \nL 120.807029 102.041845 \nL 120.921177 102.015002 \nL 121.058155 102.080706 \nL 121.080984 102.050898 \nL 121.172302 101.99288 \nL 121.195132 102.02415 \nL 121.400598 102.122174 \nL 121.423427 102.092503 \nL 121.469087 102.154716 \nL 121.81153 102.437265 \nL 121.857189 102.378102 \nL 121.925678 102.47048 \nL 122.062655 102.474065 \nL 122.176803 102.386881 \nL 122.222462 102.44819 \nL 122.290951 102.54 \nL 122.359439 102.451806 \nL 122.542076 102.396817 \nL 122.610564 102.428528 \nL 122.656223 102.370069 \nL 122.975837 102.141215 \nL 123.135644 102.175723 \nL 123.249792 102.149574 \nL 123.272621 102.179834 \nL 123.432428 102.214111 \nL 123.569406 102.100378 \nL 123.615065 102.160625 \nL 123.637894 102.190727 \nL 123.706383 102.104615 \nL 123.797701 102.107422 \nL 123.820531 102.137462 \nL 124.025997 102.289897 \nL 124.048826 102.261299 \nL 124.39127 102.009177 \nL 124.642395 102.220062 \nL 124.665224 102.191747 \nL 124.89352 102.082872 \nL 125.030497 102.202356 \nL 125.076156 102.146062 \nL 125.350111 101.982008 \nL 125.578407 102.160856 \nL 125.601236 102.13293 \nL 125.852361 101.997906 \nL 126.057827 102.089569 \nL 126.400271 101.845386 \nL 126.560077 101.878906 \nL 126.742714 101.772344 \nL 126.765543 101.801247 \nL 126.811203 101.859002 \nL 126.879691 101.777022 \nL 127.016669 101.78168 \nL 127.244964 101.901154 \nL 127.313453 101.819616 \nL 127.381941 101.905549 \nL 127.45043 101.935598 \nL 127.496089 101.881366 \nL 127.518919 101.854271 \nL 127.587407 101.93992 \nL 127.610237 101.968445 \nL 127.678726 101.887254 \nL 127.792873 101.918649 \nL 127.907021 101.94994 \nL 127.929851 101.922981 \nL 128.203805 101.766172 \nL 128.340783 101.825809 \nL 128.363612 101.799039 \nL 128.409271 101.745564 \nL 128.47776 101.830277 \nL 128.728885 101.975311 \nL 128.843033 102.006118 \nL 129.071329 102.121943 \nL 129.390942 101.913939 \nL 129.52792 101.972346 \nL 129.550749 101.945965 \nL 129.710556 101.923833 \nL 130.00734 102.12128 \nL 130.258465 101.994215 \nL 130.441102 102.106623 \nL 130.463931 102.080516 \nL 130.737886 101.928396 \nL 131.080329 102.177468 \nL 131.217307 102.181148 \nL 131.377114 102.21185 \nL 131.651068 102.061076 \nL 131.765216 102.090579 \nL 131.788046 102.064934 \nL 131.856534 101.988086 \nL 131.925023 102.068783 \nL 132.039171 102.045777 \nL 132.062 102.020238 \nL 132.130489 102.100693 \nL 132.313125 102.157912 \nL 132.518591 102.08529 \nL 132.701228 102.142267 \nL 132.906694 102.070044 \nL 133.11216 102.153212 \nL 133.271967 102.028534 \nL 133.317626 102.081347 \nL 133.454603 102.136536 \nL 133.477433 102.111428 \nL 133.660069 102.065029 \nL 133.682899 102.091304 \nL 133.751387 102.016285 \nL 133.842706 101.967646 \nL 133.888365 102.020112 \nL 134.093831 102.204438 \nL 134.13949 102.15461 \nL 134.322126 102.057616 \nL 134.344956 102.083671 \nL 134.550422 102.165293 \nL 134.687399 102.168836 \nL 134.824377 102.222922 \nL 134.847206 102.198224 \nL 135.052672 102.127799 \nL 135.121161 102.154779 \nL 135.16682 102.105614 \nL 135.280968 102.133761 \nL 135.577752 102.316761 \nL 135.760388 102.271108 \nL 135.806047 102.322155 \nL 135.874536 102.248913 \nL 135.920195 102.200148 \nL 135.988684 102.276607 \nL 136.19415 102.356095 \nL 136.285468 102.30855 \nL 136.331127 102.359239 \nL 136.468105 102.362372 \nL 136.71923 102.244634 \nL 136.947525 102.348641 \nL 136.970355 102.324552 \nL 137.038843 102.399919 \nL 137.130162 102.401948 \nL 137.152991 102.377891 \nL 137.358457 102.309002 \nL 137.495435 102.312177 \nL 137.609582 102.241542 \nL 137.655241 102.291464 \nL 137.906367 102.419002 \nL 138.020514 102.348577 \nL 138.066173 102.398184 \nL 138.294469 102.500088 \nL 138.362958 102.477304 \nL 138.408617 102.526636 \nL 138.614083 102.603201 \nL 138.728231 102.581311 \nL 138.75106 102.605851 \nL 139.093503 102.828375 \nL 139.25331 102.711288 \nL 139.298969 102.759969 \nL 139.367458 102.832906 \nL 139.435947 102.762345 \nL 139.687072 102.64755 \nL 139.892538 102.770199 \nL 139.915368 102.746837 \nL 140.006686 102.748414 \nL 140.029515 102.772544 \nL 140.189322 102.798945 \nL 140.212152 102.775656 \nL 140.28064 102.847795 \nL 140.371959 102.94379 \nL 140.440447 102.873975 \nL 140.554595 102.899356 \nL 140.760061 102.973103 \nL 140.897038 102.928123 \nL 140.919868 102.951949 \nL 140.965527 102.999568 \nL 141.034016 102.930184 \nL 141.35363 102.748056 \nL 141.376459 102.771797 \nL 141.444948 102.702929 \nL 141.878709 102.408624 \nL 142.038516 102.435141 \nL 142.426619 102.189234 \nL 142.791892 102.427508 \nL 142.88321 102.337548 \nL 142.951698 102.407825 \nL 143.157164 102.480721 \nL 143.40829 102.371562 \nL 143.613756 102.444163 \nL 143.773562 102.424638 \nL 144.024688 102.543018 \nL 144.38996 102.324195 \nL 144.549767 102.350113 \nL 144.778063 102.264989 \nL 144.983529 102.336728 \nL 145.097677 102.36151 \nL 145.188995 102.318654 \nL 145.303143 102.343404 \nL 145.485779 102.391791 \nL 145.805393 102.220503 \nL 146.056518 102.336802 \nL 146.307643 102.231522 \nL 146.513109 102.302125 \nL 146.741405 102.218958 \nL 146.924041 102.266829 \nL 147.038189 102.29117 \nL 147.175166 102.29404 \nL 147.266484 102.339682 \nL 147.403462 102.342479 \nL 147.51761 102.366599 \nL 147.654587 102.369343 \nL 147.951371 102.223342 \nL 148.111178 102.24845 \nL 148.293814 102.209064 \nL 148.54494 102.322302 \nL 148.636258 102.36724 \nL 148.818894 102.413861 \nL 148.910212 102.458578 \nL 149.115678 102.526731 \nL 149.412463 102.382496 \nL 149.595099 102.428707 \nL 149.869054 102.30631 \nL 150.097349 102.395755 \nL 150.279986 102.356915 \nL 150.439793 102.381182 \nL 150.850725 102.136536 \nL 151.124679 102.268396 \nL 151.284486 102.25069 \nL 151.467123 102.296248 \nL 151.58127 102.319411 \nL 151.763907 102.364696 \nL 152.037862 102.245222 \nL 152.12918 102.205542 \nL 152.357475 102.1274 \nL 152.517282 102.151519 \nL 152.677089 102.134255 \nL 152.859726 102.179382 \nL 152.996703 102.182242 \nL 153.088021 102.143013 \nL 153.293487 102.085795 \nL 153.453294 102.109757 \nL 153.567442 102.132667 \nL 153.864226 102.281759 \nL 154.275158 102.045988 \nL 154.434965 102.069771 \nL 154.549113 102.092503 \nL 154.731749 102.136852 \nL 154.891556 102.119997 \nL 155.028533 102.122878 \nL 155.119852 102.165093 \nL 155.599272 102.475653 \nL 155.73625 102.478029 \nL 155.896056 102.500782 \nL 156.078693 102.463982 \nL 156.170011 102.4257 \nL 156.398307 102.350176 \nL 156.489625 102.312114 \nL 156.695091 102.256473 \nL 156.900557 102.319821 \nL 157.037534 102.322376 \nL 157.174512 102.32492 \nL 157.357148 102.288899 \nL 157.494125 102.291485 \nL 157.608273 102.313292 \nL 157.74525 102.315836 \nL 157.859398 102.337559 \nL 157.973546 102.320063 \nL 158.110523 102.322597 \nL 158.315989 102.384936 \nL 158.452967 102.387375 \nL 158.612774 102.409676 \nL 158.77258 102.393032 \nL 158.932387 102.415248 \nL 159.069365 102.417625 \nL 159.183512 102.400245 \nL 159.388979 102.345875 \nL 159.617274 102.427077 \nL 159.754251 102.429432 \nL 159.982547 102.510182 \nL 160.119524 102.512411 \nL 160.302161 102.553679 \nL 160.461968 102.537088 \nL 160.621775 102.558737 \nL 160.804411 102.523482 \nL 160.964218 102.545078 \nL 161.146854 102.509961 \nL 161.238173 102.473466 \nL 161.397979 102.457137 \nL 161.534957 102.459408 \nL 161.694764 102.443143 \nL 161.831741 102.445424 \nL 161.945889 102.466179 \nL 162.105696 102.487639 \nL 162.197014 102.526742 \nL 162.333991 102.528908 \nL 162.493798 102.512663 \nL 162.722094 102.591173 \nL 162.90473 102.55655 \nL 163.201514 102.691595 \nL 163.338492 102.693529 \nL 163.543958 102.752167 \nL 163.726594 102.717544 \nL 164.000549 102.832339 \nL 164.114697 102.852274 \nL 164.251674 102.853987 \nL 164.388651 102.855701 \nL 164.525629 102.857415 \nL 164.845242 102.714505 \nL 164.98222 102.716387 \nL 165.096367 102.736259 \nL 165.324663 102.812456 \nL 165.507299 102.778285 \nL 165.598618 102.743009 \nL 165.735595 102.744839 \nL 165.895402 102.765152 \nL 166.146527 102.677726 \nL 166.374823 102.753324 \nL 166.580289 102.701804 \nL 166.762925 102.740381 \nL 166.968391 102.689061 \nL 167.105368 102.690932 \nL 167.242346 102.692804 \nL 167.356493 102.676412 \nL 167.584789 102.607901 \nL 167.698937 102.591636 \nL 167.813085 102.611161 \nL 167.972891 102.631295 \nL 168.087039 102.650736 \nL 168.201187 102.634502 \nL 168.406653 102.584034 \nL 168.54363 102.58601 \nL 168.703437 102.570576 \nL 168.886074 102.608637 \nL 169.06871 102.575864 \nL 169.319835 102.632399 \nL 169.479642 102.617007 \nL 169.616619 102.61892 \nL 169.913404 102.710804 \nL 170.050381 102.712602 \nL 170.278677 102.75058 \nL 170.438483 102.735155 \nL 170.552631 102.684266 \nL 170.826586 102.583445 \nL 171.169029 102.709784 \nL 171.328836 102.694528 \nL 171.62562 102.784867 \nL 171.739768 102.8381 \nL 171.990893 102.892775 \nL 172.356166 102.759454 \nL 172.858416 103.005214 \nL 173.086712 102.973419 \nL 173.315007 103.009914 \nL 173.611792 102.927945 \nL 173.771599 102.91271 \nL 173.908576 102.948132 \nL 174.159701 103.001576 \nL 174.410826 102.953484 \nL 174.753269 103.074987 \nL 174.958735 103.060141 \nL 175.118542 103.044895 \nL 175.301179 103.046682 \nL 175.438156 103.01453 \nL 175.73494 102.93399 \nL 175.986065 102.986667 \nL 176.123043 103.021364 \nL 176.305679 103.023162 \nL 176.648123 102.910512 \nL 176.922077 102.979612 \nL 177.104714 102.981473 \nL 177.241691 102.949867 \nL 177.401498 102.968004 \nL 177.584134 102.969865 \nL 177.766771 102.971737 \nL 178.109214 103.089864 \nL 178.31468 103.075397 \nL 178.542976 103.110157 \nL 178.748442 103.09571 \nL 178.953908 103.113837 \nL 179.159374 103.099432 \nL 179.296351 103.068226 \nL 179.547476 103.021984 \nL 179.798601 103.072863 \nL 180.072556 103.010902 \nL 180.278022 103.028976 \nL 180.414999 103.062433 \nL 180.643295 103.096636 \nL 180.780272 103.129924 \nL 181.077056 103.212461 \nL 181.282522 103.19813 \nL 181.465159 103.199612 \nL 181.784773 103.106761 \nL 181.990239 103.124446 \nL 182.104386 103.173022 \nL 182.241364 103.142457 \nL 182.469659 103.112754 \nL 182.720784 103.162297 \nL 182.880591 103.179383 \nL 183.154546 103.24455 \nL 183.291523 103.277018 \nL 183.656796 103.405071 \nL 183.885092 103.375232 \nL 184.364512 103.580985 \nL 184.615638 103.535553 \nL 184.889592 103.599091 \nL 185.049399 103.615356 \nL 185.232036 103.616208 \nL 185.50599 103.555678 \nL 185.688627 103.556613 \nL 185.848434 103.572826 \nL 186.076729 103.604727 \nL 186.259366 103.605578 \nL 186.55615 103.683594 \nL 186.715957 103.699555 \nL 186.875764 103.684898 \nL 187.012741 103.715999 \nL 187.172548 103.701353 \nL 187.400843 103.671797 \nL 187.651968 103.718428 \nL 187.971582 103.628668 \nL 188.222707 103.675183 \nL 188.565151 103.570913 \nL 188.816276 103.617333 \nL 189.250037 103.454089 \nL 189.387015 103.42487 \nL 189.706628 103.336949 \nL 189.843606 103.307951 \nL 190.208879 103.191127 \nL 190.368686 103.177448 \nL 190.574152 103.164158 \nL 190.825277 103.210642 \nL 190.985084 103.226655 \nL 191.281868 103.302789 \nL 191.487334 103.289404 \nL 191.647141 103.275735 \nL 192.012414 103.160541 \nL 192.21788 103.176817 \nL 192.354857 103.207214 \nL 192.537493 103.20857 \nL 192.948425 103.06544 \nL 193.085403 103.037377 \nL 193.24521 103.053338 \nL 193.473505 103.084376 \nL 193.701801 103.057175 \nL 194.067074 103.176218 \nL 194.22688 103.191895 \nL 194.455176 103.222491 \nL 194.592153 103.252352 \nL 194.797619 103.268197 \nL 195.025915 103.240965 \nL 195.208551 103.242237 \nL 195.391188 103.243509 \nL 195.550995 103.230282 \nL 195.80212 103.189087 \nL 195.939097 103.161487 \nL 196.076074 103.191096 \nL 196.28154 103.206867 \nL 196.487006 103.194092 \nL 196.669643 103.195406 \nL 196.82945 103.210778 \nL 197.240382 103.355433 \nL 197.559996 103.272529 \nL 197.765462 103.288016 \nL 198.016587 103.247357 \nL 198.290541 103.305501 \nL 198.496007 103.292758 \nL 198.701473 103.308119 \nL 198.929769 103.28155 \nL 199.089576 103.268607 \nL 199.317871 103.242174 \nL 199.500508 103.243415 \nL 199.705974 103.230871 \nL 199.91144 103.24618 \nL 200.071247 103.261152 \nL 200.276713 103.276387 \nL 200.550667 103.222765 \nL 200.824622 103.279941 \nL 201.052918 103.253803 \nL 201.326872 103.310727 \nL 201.46385 103.339105 \nL 201.669316 103.354077 \nL 201.851952 103.35516 \nL 202.103077 103.397753 \nL 202.262884 103.412337 \nL 202.46835 103.42713 \nL 202.742305 103.374023 \nL 203.084748 103.471269 \nL 203.221725 103.499163 \nL 203.404362 103.500057 \nL 203.678317 103.447149 \nL 204.066419 103.570871 \nL 204.226226 103.585075 \nL 204.386033 103.572269 \nL 204.52301 103.599827 \nL 204.774135 103.641243 \nL 205.002431 103.615241 \nL 205.116579 103.575423 \nL 205.390533 103.522978 \nL 205.778636 103.645101 \nL 205.984102 103.632537 \nL 206.212397 103.660084 \nL 206.395034 103.660757 \nL 206.6005 103.674815 \nL 206.851625 103.635891 \nL 207.07992 103.66328 \nL 207.331045 103.624504 \nL 207.605 103.678411 \nL 207.878955 103.626638 \nL 208.10725 103.65386 \nL 208.358375 103.615346 \nL 208.63233 103.668916 \nL 208.906285 103.617501 \nL 209.203069 103.684025 \nL 209.408535 103.671692 \nL 209.636831 103.698566 \nL 209.933615 103.634513 \nL 210.116251 103.635207 \nL 210.321717 103.623 \nL 210.550013 103.649801 \nL 210.732649 103.650464 \nL 210.915286 103.651137 \nL 211.257729 103.562081 \nL 211.577343 103.640664 \nL 211.828468 103.603034 \nL 212.011104 103.603759 \nL 212.330718 103.52813 \nL 212.559014 103.554721 \nL 212.76448 103.542819 \nL 212.924287 103.530738 \nL 213.198241 103.480963 \nL 213.449366 103.494863 \nL 213.700491 103.457905 \nL 213.928787 103.458999 \nL 214.111423 103.485211 \nL 214.431037 103.537257 \nL 214.682162 103.525712 \nL 215.070265 103.615546 \nL 215.344219 103.591437 \nL 215.526856 103.567043 \nL 215.800811 103.543081 \nL 216.074765 103.569262 \nL 216.32589 103.55778 \nL 216.554186 103.558716 \nL 216.805311 103.547287 \nL 217.102095 103.585822 \nL 217.284732 103.611382 \nL 217.604345 103.662166 \nL 217.923959 103.613769 \nL 218.197914 103.639497 \nL 218.426209 103.640307 \nL 218.722994 103.678295 \nL 218.90563 103.703487 \nL 219.225244 103.753598 \nL 219.590517 103.681155 \nL 219.773153 103.657277 \nL 220.092767 103.609532 \nL 220.298233 103.598103 \nL 220.45804 103.635249 \nL 220.640676 103.611561 \nL 221.005949 103.540043 \nL 221.279904 103.565414 \nL 221.48537 103.578325 \nL 221.690836 103.567022 \nL 222.056109 103.496062 \nL 222.352893 103.533482 \nL 222.53553 103.558285 \nL 222.855143 103.607586 \nL 223.174757 103.560809 \nL 223.448712 103.585811 \nL 223.608519 103.622275 \nL 223.905303 103.659127 \nL 224.06511 103.695423 \nL 224.361894 103.732054 \nL 224.635849 103.70907 \nL 224.818485 103.685886 \nL 225.138099 103.639508 \nL 225.412054 103.66409 \nL 225.800156 103.582752 \nL 226.005622 103.571733 \nL 226.302406 103.537551 \nL 226.850316 103.703939 \nL 227.078611 103.704623 \nL 227.329736 103.717071 \nL 227.535202 103.729352 \nL 227.763498 103.730004 \nL 228.060282 103.695906 \nL 228.448384 103.778422 \nL 228.67668 103.779 \nL 228.927805 103.791229 \nL 229.156101 103.791786 \nL 229.361567 103.780735 \nL 229.498544 103.827282 \nL 229.68118 103.804613 \nL 229.955135 103.782228 \nL 230.22909 103.805917 \nL 230.548704 103.760748 \nL 230.75417 103.749813 \nL 231.165102 103.65938 \nL 231.370568 103.648613 \nL 231.713011 103.592688 \nL 232.078284 103.662282 \nL 232.489216 103.572721 \nL 232.877318 103.65345 \nL 233.105614 103.654175 \nL 233.28825 103.632148 \nL 233.448057 103.666561 \nL 233.676353 103.667265 \nL 233.83616 103.701573 \nL 234.110114 103.724873 \nL 234.33841 103.725504 \nL 234.521046 103.70355 \nL 234.84066 103.659643 \nL 235.160274 103.70539 \nL 235.411399 103.694928 \nL 235.639694 103.695601 \nL 235.913649 103.67411 \nL 236.278922 103.741917 \nL 236.530047 103.731476 \nL 237.100786 103.899031 \nL 237.306252 103.91045 \nL 237.762843 104.021501 \nL 238.013968 104.010756 \nL 238.242264 104.011019 \nL 238.379241 104.055136 \nL 238.744514 104.121282 \nL 239.018469 104.099528 \nL 239.269594 104.11062 \nL 239.45223 104.132584 \nL 239.703355 104.143614 \nL 239.954481 104.132826 \nL 240.388242 104.230872 \nL 240.548049 104.26345 \nL 240.913322 104.328407 \nL 241.164447 104.317436 \nL 241.347083 104.295708 \nL 241.598209 104.284805 \nL 241.803675 104.273943 \nL 242.146118 104.22 \nL 242.420073 104.241507 \nL 242.831005 104.155621 \nL 243.013641 104.134246 \nL 243.196277 104.155747 \nL 243.493062 104.187921 \nL 243.812675 104.145286 \nL 244.040971 104.14537 \nL 244.383414 104.092294 \nL 244.634539 104.103092 \nL 244.908494 104.082042 \nL 245.159619 104.09282 \nL 245.342256 104.114121 \nL 245.593381 104.124835 \nL 245.867335 104.103849 \nL 246.14129 104.125109 \nL 246.415245 104.104185 \nL 246.826177 104.188478 \nL 247.031643 104.199014 \nL 247.396916 104.261899 \nL 247.739359 104.209538 \nL 248.036143 104.240881 \nL 248.241609 104.251285 \nL 248.424246 104.23042 \nL 248.675371 104.22 \nL 248.926496 104.230393 \nL 249.086303 104.261537 \nL 249.291769 104.251117 \nL 249.497235 104.261447 \nL 249.74836 104.271741 \nL 249.930996 104.29237 \nL 250.136462 104.281966 \nL 250.456076 104.240624 \nL 250.661542 104.230299 \nL 250.889838 104.230288 \nL 251.186622 104.26109 \nL 251.574724 104.189246 \nL 252.031315 104.291597 \nL 252.350929 104.250633 \nL 252.602054 104.260795 \nL 252.921668 104.22 \nL 253.058645 104.179299 \nL 253.195623 104.22 \nL 253.515237 104.260606 \nL 253.766362 104.250418 \nL 254.131635 104.311085 \nL 254.428419 104.300844 \nL 254.816521 104.351113 \nL 255.090476 104.350934 \nL 255.501408 104.410976 \nL 255.821022 104.390599 \nL 256.140635 104.410366 \nL 256.551567 104.349988 \nL 256.985329 104.41955 \nL 257.282113 104.409293 \nL 257.624557 104.438807 \nL 257.967 104.408652 \nL 258.355102 104.457843 \nL 258.811693 104.378208 \nL 259.176966 104.417405 \nL 259.49658 104.397386 \nL 259.770535 104.397149 \nL 260.272785 104.298542 \nL 260.820694 104.415828 \nL 261.07182 104.425365 \nL 261.459922 104.473783 \nL 261.848024 104.424597 \nL 262.121979 104.424324 \nL 262.555741 104.355934 \nL 262.966673 104.413804 \nL 263.172139 104.442655 \nL 263.491752 104.461644 \nL 263.697218 104.490374 \nL 263.925514 104.470786 \nL 264.267957 104.441488 \nL 264.541912 104.441199 \nL 264.861526 104.421653 \nL 265.112651 104.411822 \nL 265.363776 104.421175 \nL 265.637731 104.420912 \nL 265.934515 104.411076 \nL 266.276958 104.43938 \nL 266.619402 104.410455 \nL 266.870527 104.400719 \nL 267.21297 104.371936 \nL 267.532584 104.390673 \nL 267.806538 104.390452 \nL 268.126152 104.409109 \nL 268.354448 104.427799 \nL 268.628402 104.42753 \nL 268.902357 104.427262 \nL 269.153482 104.41761 \nL 269.358948 104.445625 \nL 269.701392 104.47342 \nL 270.043835 104.444905 \nL 270.409108 104.481942 \nL 270.660233 104.490984 \nL 271.116824 104.565004 \nL 271.482097 104.52719 \nL 271.710392 104.508264 \nL 272.007177 104.498586 \nL 272.189813 104.461239 \nL 272.555086 104.423782 \nL 272.8747 104.441982 \nL 273.057336 104.478761 \nL 273.331291 104.478435 \nL 273.628075 104.468867 \nL 273.8792 104.459373 \nL 274.198814 104.440636 \nL 274.495598 104.449521 \nL 274.815212 104.430853 \nL 275.157655 104.457985 \nL 275.43161 104.457685 \nL 275.637076 104.430064 \nL 276.025178 104.384112 \nL 276.299133 104.383907 \nL 276.664406 104.347275 \nL 276.98402 104.365244 \nL 277.417781 104.301543 \nL 277.691736 104.301438 \nL 278.034179 104.274212 \nL 278.285304 104.265122 \nL 278.673407 104.22 \nL 279.107169 104.282944 \nL 279.312635 104.309834 \nL 279.700737 104.354519 \nL 280.04318 104.32745 \nL 280.362794 104.345183 \nL 280.728067 104.309271 \nL 281.390124 104.460324 \nL 281.778227 104.415486 \nL 282.052181 104.41525 \nL 282.326136 104.415013 \nL 282.714238 104.458926 \nL 283.056682 104.432062 \nL 283.330636 104.431804 \nL 283.467614 104.431678 \nL 283.467614 104.431678 \n\" clip-path=\"url(#p12b8914372)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 43.78125 104.22 \nL 294.88125 104.22 \n\" clip-path=\"url(#p12b8914372)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 201.24 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 201.24 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 182.759375 44.55625 \nL 287.88125 44.55625 \nQ 289.88125 44.55625 289.88125 42.55625 \nL 289.88125 14.2 \nQ 289.88125 12.2 287.88125 12.2 \nL 182.759375 12.2 \nQ 180.759375 12.2 180.759375 14.2 \nL 180.759375 42.55625 \nQ 180.759375 44.55625 182.759375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 184.759375 20.298438 \nL 194.759375 20.298438 \nL 204.759375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- P(coin=heads) -->\n     <g transform=\"translate(212.759375 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 184.759375 34.976562 \nL 194.759375 34.976562 \nL 204.759375 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- P(coin=tails) -->\n     <g transform=\"translate(212.759375 38.476562) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p12b8914372\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"194.04\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Documentation"
      ],
      "metadata": {
        "id": "1p9DriZkoaFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "dwjh7PCcobpI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(torch.distributions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_liih3moo23",
        "outputId": "03aa972e-a16e-446d-d7e6-5982def5e67a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'InverseGamma', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PositiveDefiniteTransform', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'inverse_gamma', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(torch.ones)"
      ],
      "metadata": {
        "id": "-SWiCDZqpS7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}